{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_SI_Task_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2e38997a17747dc95cc95c94b7e0f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94d0ea7ab1aa4f429580242bc7006a44",
              "IPY_MODEL_c5be829e32b24ce6be48cf078092478f",
              "IPY_MODEL_a525c82820904bbd9ec08036f1a9f289"
            ],
            "layout": "IPY_MODEL_74277cfb536b4b51be28dcb1754ea98e"
          }
        },
        "94d0ea7ab1aa4f429580242bc7006a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bd78e80f9884fdc8e019276d52cd99e",
            "placeholder": "​",
            "style": "IPY_MODEL_383c45f6b2a54653957b94bf2971e4aa",
            "value": "Downloading: 100%"
          }
        },
        "c5be829e32b24ce6be48cf078092478f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5ce9d5639144559912d52cd21975fed",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4fcb6c738814b3a94ea1b474049f03c",
            "value": 231508
          }
        },
        "a525c82820904bbd9ec08036f1a9f289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb3d67de0fc040af90c7d76590c66d06",
            "placeholder": "​",
            "style": "IPY_MODEL_300581fd54534eeba96424ba5d0e8626",
            "value": " 232k/232k [00:00&lt;00:00, 1.56MB/s]"
          }
        },
        "74277cfb536b4b51be28dcb1754ea98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd78e80f9884fdc8e019276d52cd99e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "383c45f6b2a54653957b94bf2971e4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5ce9d5639144559912d52cd21975fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4fcb6c738814b3a94ea1b474049f03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb3d67de0fc040af90c7d76590c66d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300581fd54534eeba96424ba5d0e8626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6e8cb3fbb314a5582a93bf83d6f9f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_995f4496249644568cf545b768cd1ad0",
              "IPY_MODEL_e28fa0abf2364d3bb72f32dc57ce341a",
              "IPY_MODEL_965af4515922439b8fec3b4fc633f62f"
            ],
            "layout": "IPY_MODEL_fc42aea8d70946078cee1c0fc429f9db"
          }
        },
        "995f4496249644568cf545b768cd1ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06050eae2424f92a43040fa0566c1e4",
            "placeholder": "​",
            "style": "IPY_MODEL_302193092e47432aa5b76c1ec00e571f",
            "value": "Downloading: 100%"
          }
        },
        "e28fa0abf2364d3bb72f32dc57ce341a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39cc5e2ae0514cf1a4b261217788f811",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c18444ba0dba493f86d3b34d6804b712",
            "value": 433
          }
        },
        "965af4515922439b8fec3b4fc633f62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aefb9a3ee1e419e8f6f5a8d1adccdb0",
            "placeholder": "​",
            "style": "IPY_MODEL_217a363439f94dbda519e5d9b4d8d5d7",
            "value": " 433/433 [00:00&lt;00:00, 2.36kB/s]"
          }
        },
        "fc42aea8d70946078cee1c0fc429f9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06050eae2424f92a43040fa0566c1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "302193092e47432aa5b76c1ec00e571f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39cc5e2ae0514cf1a4b261217788f811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18444ba0dba493f86d3b34d6804b712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1aefb9a3ee1e419e8f6f5a8d1adccdb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217a363439f94dbda519e5d9b4d8d5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbf99f8ae0714f888e667b308fbdeb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18da7189057844e08b81ce1c98fed3f5",
              "IPY_MODEL_141b4dd609074d95bff4bbb6a80cda0f",
              "IPY_MODEL_abb2d93484c04b3eafb2ffc3c8f9cb3b"
            ],
            "layout": "IPY_MODEL_f5c488bef56441c585606d646ec0a963"
          }
        },
        "18da7189057844e08b81ce1c98fed3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cad6af4dc11f44508fb8b7a3ff089e12",
            "placeholder": "​",
            "style": "IPY_MODEL_4cbd80dbeb8145f89aec1bbfe0736e37",
            "value": "Downloading: 100%"
          }
        },
        "141b4dd609074d95bff4bbb6a80cda0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_069e96cd98a34eb7a63b6febcba59589",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bb18647f61e4457a0b18c7bb137eaa9",
            "value": 440473133
          }
        },
        "abb2d93484c04b3eafb2ffc3c8f9cb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_392b9b695a694a8d8ee7ef0aeee3008b",
            "placeholder": "​",
            "style": "IPY_MODEL_709e71e0c3434078b49c1c680352f5ec",
            "value": " 440M/440M [00:10&lt;00:00, 43.1MB/s]"
          }
        },
        "f5c488bef56441c585606d646ec0a963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cad6af4dc11f44508fb8b7a3ff089e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbd80dbeb8145f89aec1bbfe0736e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069e96cd98a34eb7a63b6febcba59589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb18647f61e4457a0b18c7bb137eaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "392b9b695a694a8d8ee7ef0aeee3008b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "709e71e0c3434078b49c1c680352f5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYb4b2dbXqY7"
      },
      "outputs": [],
      "source": [
        "#  !pip install transformers seqeval[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==3.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6yIqY1uXUyl",
        "outputId": "4b750131-ecdb-4ade-b515-d70dee14252c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.1.0\n",
            "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 884 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 38.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 35.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=2557791b251217c8c1e7f73a698bf2229a7b1b8fb83007df51d04c184c593e3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import regex as re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import cuda\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import glob\n",
        "import os.path\n",
        "import numpy as np\n",
        "import sys\n",
        "import codecs"
      ],
      "metadata": {
        "id": "1WkJISARMfdS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMJAleGYNglf",
        "outputId": "66a12ccc-5f50-41dc-f68a-91bb58a0bd8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9rBtiyiXq3p",
        "outputId": "57ca1eeb-13ca-4a06-fc4e-d929601298aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder = \"/content/drive/MyDrive/NLP/project_5_data/datasets/train-articles\" \n",
        "dev_folder = \"/content/drive/MyDrive/NLP/project_5_data/datasets/dev-articles\"    \n",
        "train_labels_file = \"/content/drive/MyDrive/NLP/project_5_data/datasets/train-labels-task-si/\"\n",
        "dev_labels_file = \"/content/drive/MyDrive/NLP/project_5_data/datasets/dev-labels-task-si\"\n",
        "task_TC_output_file = \"/content/drive/MyDrive/NLP/project_5_data/baseline-output-TC.txt\""
      ],
      "metadata": {
        "id": "N10O1opYXyjM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def read_articles_from_file_list(folder_name, file_pattern=\"*.txt\"):\n",
        "    \"\"\"\n",
        "    Read articles from files matching patterns <file_pattern> from  \n",
        "    the directory <folder_name>. \n",
        "    The content of the article is saved in the dictionary whose key\n",
        "    is the id of the article (extracted from the file name).\n",
        "    Each element of <sentence_list> is one line of the article.\n",
        "    \"\"\"\n",
        "    file_list = glob.glob(os.path.join(folder_name, file_pattern))\n",
        "    print(folder_name, len(file_list))\n",
        "    articles = {}\n",
        "    article_id_list, sentence_id_list, sentence_list = ([], [], [])\n",
        "    for filename in sorted(file_list):\n",
        "        article_id = os.path.basename(filename).split(\".\")[0][7:]\n",
        "        with codecs.open(filename, \"r\", encoding=\"utf8\") as f:\n",
        "          # sentence = ' '.join([line.strip() for line in f if len(line) >= 1])\n",
        "          # articles[article_id] = sentence\n",
        "          sentence = f.read().strip()\n",
        "          sentence = sentence.replace('\\n\\n', ' ').strip().replace('\\n', ' ').strip()\n",
        "          articles[article_id] = sentence\n",
        "    return articles\n",
        "\n",
        "\n",
        "def read_labels_from_file_list(folder_name, file_pattern=\"*.txt\"):\n",
        "\n",
        "    file_list = glob.glob(os.path.join(folder_name, file_pattern))\n",
        "    print(folder_name, len(file_list))\n",
        "    labels = {}\n",
        "    for filename in sorted(file_list):\n",
        "        article_id = os.path.basename(filename).split(\".\")[0][7:]\n",
        "        if article_id not in labels:\n",
        "          labels[article_id] = []\n",
        "        with codecs.open(filename, \"r\", encoding=\"utf8\") as f:\n",
        "          for line in f:\n",
        "            line_values = line.strip().split('\\t')\n",
        "            article_id = line_values[0]\n",
        "            start = line_values[1]\n",
        "            end = line_values[2]\n",
        "            labels[article_id].append((article_id, start, end))\n",
        "    return labels"
      ],
      "metadata": {
        "id": "iHIyOpGKGz2r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = read_labels_from_file_list('/content/drive/MyDrive/NLP/project_5_data/datasets/dev-labels-task-si','*.labels')"
      ],
      "metadata": {
        "id": "oCtHqDPvuKrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc9e386-f87b-414a-d5ec-0d3834b0c50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/project_5_data/datasets/dev-labels-task-si 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a['730246508']"
      ],
      "metadata": {
        "id": "0nChME92uphi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8b6693-20ec-4f46-bda0-131b460da226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('730246508', '1654', '1676'),\n",
              " ('730246508', '4557', '4573'),\n",
              " ('730246508', '4406', '4412'),\n",
              " ('730246508', '3840', '3948'),\n",
              " ('730246508', '4187', '4195'),\n",
              " ('730246508', '5052', '5098')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_folder = \"/content/drive/MyDrive/NLP/project_5_data/datasets/dev-articles\" # check that the path to the datasets folder is correct, if not adjust these variables accordingly \n",
        "propaganda_techniques_file = \"/content/drive/MyDrive/NLP/project_5_data/propaganda-techniques-scorer/data/propaganda-techniques-names-semeval2020task11.txt\" # propaganda_techniques_file is in the tools.tgz file (download it from the team page)\n",
        "task_SI_output_file = \"/content/drive/MyDrive/NLP/project_5_data/baseline-output-SI.txt\""
      ],
      "metadata": {
        "id": "vqC8_wk6M2d7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 task-SI_scorer.py -s project_5_data/baseline-output-SI.txt -r project_5_data/datasets/dev-labels-task-si/"
      ],
      "metadata": {
        "id": "YU4Zg6aieW_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = glob.glob(os.path.join(train_folder, \"*.txt\"))\n",
        "train_articles_content, train_articles_id = ([], [])\n",
        "for filename in file_list:\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        train_articles_content.append(' '.join([line.strip() for line in f]))\n",
        "        train_articles_id.append(os.path.basename(filename).split(\".\")[0][7:])\n"
      ],
      "metadata": {
        "id": "Bg0jS7l3eZLB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_articles = read_articles_from_file_list(train_folder)\n",
        "dev_articles = read_articles_from_file_list(dev_folder)"
      ],
      "metadata": {
        "id": "t82UPVQizKnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340e3351-7a0c-47ab-b8ad-3c9f9a831f1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/project_5_data/datasets/train-articles 371\n",
            "/content/drive/MyDrive/NLP/project_5_data/datasets/dev-articles 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_articles['111111121']\n",
        "dev_articles['730081389']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Zf831_VA14LU",
        "outputId": "5b582f78-b842-43ae-8409-d9f4c5f7340a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Police had previously gone to home where Ohio patrol officers were killed CLEVELAND — Police invstigating domestic disputes had previously gone to the home where a man fatally shot two police officers over the weekend, but no arrests were ever made, police reports from the Columbus suburb of Westerville show. Westerville Officers Eric Joering, 39, and Anthony Morelli, 54, were killed shortly after noon Saturday in this normally quiet suburb while responding to a 911 hang-up call. The suspect, 30-year-old Quentin Smith, was shot and wounded by the officers and taken to Ohio State University Wexner Medical Center in critical condition Saturday. Advertisement A series of 911 calls released by the city of Westerville provide some details about what happened Saturday at a complex of town houses. Smith lived there with his wife, Candace, and a young daughter. Get Ground Game in your inbox: Daily updates and analysis on national politics from James Pindell. Sign Up Thank you for signing up! Sign up for more newsletters here Westerville Police Chief Joe Morbitzer said at a news conference Saturday that Joering and Morelli were shot immediately upon entering. After the initial hang-up call at noon, a dispatcher called the number back and reached a woman who was crying and could be heard saying, ‘‘won’t let me in.’’ Officers were then sent to the home. At 12:12 p.m., an officer tells a dispatcher that it’s ‘‘all quiet right now,’’ followed by a door knock. At 12:13 p.m., after a dispatcher confirmed contact has been made, a man’s voice could be heard yelling, ‘‘We have shots fired.’’ Four minutes later, someone, presumably a police officer, told a dispatcher: ‘‘We have two officers down. Child on couch, one at gunpoint.’’ Advertisement ASSOCIATED PRESS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_articles))\n",
        "print(len(dev_articles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id1Ewcgy0AHU",
        "outputId": "d6f7a168-74ec-42c2-b1c8-75a6f7246712"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371\n",
            "75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TASK_3_ARTICLE_ID_COL=0\n",
        "#TASK_3_TECHNIQUE_NAME_COL=1\n",
        "TASK_3_FRAGMENT_START_COL=1\n",
        "TASK_3_FRAGMENT_END_COL=2\n",
        "def extract_article_id_from_file_name(fullpathfilename):\n",
        "\n",
        "    regex = re.compile(\"article([0-9]+).*\")\n",
        "    return regex.match(os.path.basename(fullpathfilename)).group(1)\n",
        "\n",
        "   \n",
        "def load_annotation_list_from_folder(folder_name, techniques_names):\n",
        "\n",
        "    file_list = glob.glob(os.path.join(folder_name, \"*.labels\"))\n",
        "    if len(file_list)==0:\n",
        "        print(\"Cannot load file list in folder \" + folder_name)\n",
        "        sys.exit()\n",
        "    annotations = {}\n",
        "    for filename in file_list:\n",
        "        annotations[extract_article_id_from_file_name(filename)] = []\n",
        "        with open(filename, \"r\") as f:\n",
        "            for row_number, line in enumerate(f.readlines()):\n",
        "                row = line.rstrip().split(\"\\t\")\n",
        "                annotations[row[TASK_3_ARTICLE_ID_COL]].append((row[TASK_3_FRAGMENT_START_COL],row[TASK_3_FRAGMENT_END_COL]))\n",
        "    return annotations"
      ],
      "metadata": {
        "id": "jCD14ScF0DRa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "techniques_names = [ \"propaganda\" ]\n",
        "train_annotation = load_annotation_list_from_folder(train_labels_file, techniques_names)\n",
        "new_annotations = read_labels_from_file_list(train_labels_file,'*.labels')"
      ],
      "metadata": {
        "id": "Oj4NcyRg2TMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abf905a-7465-4364-f8dd-281a8a4c7161"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/project_5_data/datasets/train-labels-task-si/ 371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_annotation.keys(), new_annotations.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvJI2Qrf2atf",
        "outputId": "c08f1750-01cf-446a-f6c7-8a1822db6718"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict_keys(['736757214', '790720480', '754179642', '729651527', '712382330', '787668628', '721710340', '715588833', '755814432', '727128296', '111111124', '782086447', '758512204', '761780613', '778139122', '111111112', '790777028', '732708002', '789121798', '698092698', '727569885', '757713354', '793467906', '704591553', '697444415', '723501118', '770376380', '725276027', '758882558', '694356862', '757243988', '774007496', '696246189', '762200179', '789370998', '729549972', '728972961', '706088110', '731063195', '701447437', '710376094', '999000870', '729303442', '715790840', '721890296', '787955075', '725498022', '707451080', '781768042', '999001296', '999000155', '764664283', '763260610', '727736595', '999000159', '795693029', '999000133', '752287274', '758472954', '721406153', '795079843', '730389374', '727736557', '773748383', '700461600', '708071969', '766942310', '707772906', '769962236', '729668796', '758386255', '776345502', '697454736', '702077434', '788816478', '728758697', '704856340', '111111114', '730222442', '761897089', '999000124', '999000149', '757843275', '762147609', '999000142', '736231219', '723823436', '786250729', '701939679', '705035735', '737194975', '727174208', '759478604', '737457870', '770938827', '790677230', '999000565', '758385628', '778664280', '694811415', '781847297', '761969692', '793921939', '698503276', '732154721', '780787440', '754348478', '761968851', '786344683', '788900262', '701933838', '793534424', '999000675', '758669180', '766632016', '701299732', '764609985', '780786973', '699291100', '699478811', '710100700', '771879020', '723844295', '999001226', '786731884', '729348908', '724095598', '999000894', '782149225', '999001621', '703821117', '999001287', '727497152', '711566593', '729700539', '111111134', '765982381', '711716996', '698780559', '766084411', '789121265', '999000136', '776616374', '775448623', '727634031', '770156851', '770581969', '730268758', '999000158', '739140767', '777488669', '700662577', '757964238', '795691173', '790665855', '771655795', '795689901', '695108099', '758469195', '999001619', '738060046', '758756657', '770221823', '708487008', '730865684', '999000147', '706661242', '698719689', '111111115', '708561738', '703806098', '999000135', '790483991', '999001970', '795379208', '111111136', '698018235', '706501640', '770156173', '728169864', '696735702', '740356006', '729940206', '730652769', '697996062', '771406408', '757611486', '730061195', '761564397', '755170235', '774637726', '741896049', '762152527', '780414700', '773937361', '729368012', '700551604', '754131438', '727493378', '790720714', '790667730', '706636401', '741655444', '731511020', '695833178', '779394730', '729578579', '999000154', '771546417', '754111899', '795703371', '740808926', '730573740', '773520636', '774904810', '111111117', '999000312', '788173482', '755393220', '735265649', '706777811', '762956953', '111111132', '730019938', '765385479', '770877978', '718595845', '111111121', '761334950', '770945799', '790266787', '729581752', '737255982', '731927633', '707566605', '741802985', '111111131', '739091070', '758812201', '705409419', '763761219', '769427494', '754508491', '999001297', '735815503', '761546223', '734265267', '758477392', '761969038', '741923579', '757171650', '724791253', '730559808', '776373795', '999000849', '999000880', '769682854', '787142429', '729670169', '711596363', '763440871', '785801366', '718312499', '999001241', '703698295', '762340819', '730036755', '735090638', '716469423', '999000184', '787529309', '761674108', '776535164', '765913191', '729410793', '733754480', '782017101', '725731328', '701225819', '786919720', '769752554', '111111135', '776049384', '786527921', '999001188', '727869189', '732610971', '730237078', '788056108', '731513824', '711622457', '762206044', '111111113', '696264594', '770956434', '697959084', '725238842', '697472447', '769962328', '727405181', '731762731', '762160164', '756114837', '787759779', '764715911', '754231597', '711964584', '694327499', '735855251', '701553469', '723793978', '759468687', '723883127', '761610997', '728343601', '999000599', '697063039', '713130996', '999001293', '765197039', '776368676', '787002327', '781577820', '111111122', '722507879', '702077783', '724095467', '764518567', '999000125', '728680557', '771254016', '999000145', '738207834', '735815173', '730149656', '762546428', '706600938', '703056647', '728153988', '729561658', '765953146', '111111111', '774145019', '765029945', '755459860', '722512241', '759337941', '788726416', '699142854', '111111137', '789370909', '761874505', '701837665', '789615291', '780619695', '772947654', '723537899', '754402671', '731178960', '767129999', '999001033', '111111133', '999001032', '700387229', '725824328', '727658675', '111111123', '783702663', '709732928', '696694316', '702111021']),\n",
              " dict_keys(['111111111', '111111112', '111111113', '111111114', '111111115', '111111117', '111111121', '111111122', '111111123', '111111124', '111111131', '111111132', '111111133', '111111134', '111111135', '111111136', '111111137', '694327499', '694356862', '694811415', '695108099', '695833178', '696246189', '696264594', '696694316', '696735702', '697063039', '697444415', '697454736', '697472447', '697959084', '697996062', '698018235', '698092698', '698503276', '698719689', '698780559', '699142854', '699291100', '699478811', '700387229', '700461600', '700551604', '700662577', '701225819', '701299732', '701447437', '701553469', '701837665', '701933838', '701939679', '702077434', '702077783', '702111021', '703056647', '703698295', '703806098', '703821117', '704591553', '704856340', '705035735', '705409419', '706088110', '706501640', '706600938', '706636401', '706661242', '706777811', '707451080', '707566605', '707772906', '708071969', '708487008', '708561738', '709732928', '710100700', '710376094', '711566593', '711596363', '711622457', '711716996', '711964584', '712382330', '713130996', '715588833', '715790840', '716469423', '718312499', '718595845', '721406153', '721710340', '721890296', '722507879', '722512241', '723501118', '723537899', '723793978', '723823436', '723844295', '723883127', '724095467', '724095598', '724791253', '725238842', '725276027', '725498022', '725731328', '725824328', '727128296', '727174208', '727405181', '727493378', '727497152', '727569885', '727634031', '727658675', '727736557', '727736595', '727869189', '728153988', '728169864', '728343601', '728680557', '728758697', '728972961', '729303442', '729348908', '729368012', '729410793', '729549972', '729561658', '729578579', '729581752', '729651527', '729668796', '729670169', '729700539', '729940206', '730019938', '730036755', '730061195', '730149656', '730222442', '730237078', '730268758', '730389374', '730559808', '730573740', '730652769', '730865684', '731063195', '731178960', '731511020', '731513824', '731762731', '731927633', '732154721', '732610971', '732708002', '733754480', '734265267', '735090638', '735265649', '735815173', '735815503', '735855251', '736231219', '736757214', '737194975', '737255982', '737457870', '738060046', '738207834', '739091070', '739140767', '740356006', '740808926', '741655444', '741802985', '741896049', '741923579', '752287274', '754111899', '754131438', '754179642', '754231597', '754348478', '754402671', '754508491', '755170235', '755393220', '755459860', '755814432', '756114837', '757171650', '757243988', '757611486', '757713354', '757843275', '757964238', '758385628', '758386255', '758469195', '758472954', '758477392', '758512204', '758669180', '758756657', '758812201', '758882558', '759337941', '759468687', '759478604', '761334950', '761546223', '761564397', '761610997', '761674108', '761780613', '761874505', '761897089', '761968851', '761969038', '761969692', '762147609', '762152527', '762160164', '762200179', '762206044', '762340819', '762546428', '762956953', '763260610', '763440871', '763761219', '764518567', '764609985', '764664283', '764715911', '765029945', '765197039', '765385479', '765913191', '765953146', '765982381', '766084411', '766632016', '766942310', '767129999', '769427494', '769682854', '769752554', '769962236', '769962328', '770156173', '770156851', '770221823', '770376380', '770581969', '770877978', '770938827', '770945799', '770956434', '771254016', '771406408', '771546417', '771655795', '771879020', '772947654', '773520636', '773748383', '773937361', '774007496', '774145019', '774637726', '774904810', '775448623', '776049384', '776345502', '776368676', '776373795', '776535164', '776616374', '777488669', '778139122', '778664280', '779394730', '780414700', '780619695', '780786973', '780787440', '781577820', '781768042', '781847297', '782017101', '782086447', '782149225', '783702663', '785801366', '786250729', '786344683', '786527921', '786731884', '786919720', '787002327', '787142429', '787529309', '787668628', '787759779', '787955075', '788056108', '788173482', '788726416', '788816478', '788900262', '789121265', '789121798', '789370909', '789370998', '789615291', '790266787', '790483991', '790665855', '790667730', '790677230', '790720480', '790720714', '790777028', '793467906', '793534424', '793921939', '795079843', '795379208', '795689901', '795691173', '795693029', '795703371', '999000124', '999000125', '999000133', '999000135', '999000136', '999000142', '999000145', '999000147', '999000149', '999000154', '999000155', '999000158', '999000159', '999000184', '999000312', '999000565', '999000599', '999000675', '999000849', '999000870', '999000880', '999000894', '999001032', '999001033', '999001188', '999001226', '999001241', '999001287', '999001293', '999001296', '999001297', '999001619', '999001621', '999001970']))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = {}\n",
        "for article in train_articles.keys():\n",
        "    labels = [0] * len(train_articles[article])\n",
        "    for annot in train_annotation[article]:\n",
        "        labels[int(annot[0]) : int(annot[1])] = [1] * (int(annot[1]) - int(annot[0]))\n",
        "    train_labels[article] = labels"
      ],
      "metadata": {
        "id": "bTc14E5gHXOG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels['111111111']\n",
        "len(train_articles['111111111'].split(' '))"
      ],
      "metadata": {
        "id": "iR3EYhJbzHyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11a5a08-ab34-45cf-c640-22b4eeb068dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "371"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_str = {}\n",
        "for article in train_articles.keys():\n",
        "    labels = [0] * len(train_articles[article].split(' '))\n",
        "\n",
        "    index = 0\n",
        "    \n",
        "    word_index = -1\n",
        "    for word in train_articles[article].split(' '):\n",
        "      word_index+=1\n",
        "      if(train_labels[article][index] == 1):\n",
        "        labels[word_index] = 1\n",
        "      index+= len(word) + 1\n",
        "    \n",
        "    str_labels = []\n",
        "    span_started = False\n",
        "    for label in labels:\n",
        "      if label == 0:\n",
        "        str_labels.append('O')\n",
        "        span_started = False\n",
        "      elif label == 1 and not span_started:\n",
        "        str_labels.append('I-Prop')\n",
        "        span_started = True\n",
        "      elif label == 1 and span_started:\n",
        "        str_labels.append('I-Prop')\n",
        "        span_started = True\n",
        "    train_labels[article] = labels\n",
        "    train_labels_str[article] = str_labels"
      ],
      "metadata": {
        "id": "ZDUqX-_iwf3B"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_labels(data_articles, data_annotation):\n",
        "    \n",
        "  train_labels = {}\n",
        "  for article in data_articles.keys():\n",
        "      labels = [0] * len(data_articles[article])\n",
        "      for annot in data_annotation[article]:\n",
        "          labels[int(annot[0]) : int(annot[1])] = [1] * (int(annot[1]) - int(annot[0]))\n",
        "      train_labels[article] = labels\n",
        "\n",
        "  train_labels_str = {}\n",
        "  for article in data_articles.keys():\n",
        "      labels = [0] * len(data_articles[article].split(' '))\n",
        "\n",
        "      index = 0\n",
        "      \n",
        "      word_index = -1\n",
        "      for word in data_articles[article].split(' '):\n",
        "        word_index+=1\n",
        "        if(train_labels[article][index] == 1):\n",
        "          labels[word_index] = 1\n",
        "        index+= len(word) + 1\n",
        "      \n",
        "      str_labels = []\n",
        "      span_started = False\n",
        "      for label in labels:\n",
        "        if label == 0:\n",
        "          str_labels.append('O')\n",
        "          span_started = False\n",
        "        elif label == 1 and not span_started:\n",
        "          str_labels.append('I-Prop')\n",
        "          span_started = True\n",
        "        elif label == 1 and span_started:\n",
        "          str_labels.append('I-Prop')\n",
        "          span_started = True\n",
        "      train_labels[article] = labels\n",
        "      train_labels_str[article] = str_labels\n",
        "\n",
        "  return train_labels, train_labels_str"
      ],
      "metadata": {
        "id": "EkhN8bCW6MyI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels), len(train_labels_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOYRjFdxItAR",
        "outputId": "9e9ea24e-335a-4a93-cd91-8a7104350bbe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(371, 371)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(train_labels['111111111'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8KGnC4UIvVj",
        "outputId": "1101fb19-d34c-4ab0-c39b-414ff54ca335"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_annotation['111111111'], train_articles['111111111']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta8Vyk-XyF9q",
        "outputId": "0dd5f739-978b-4c51-b24e-f6965e7aced2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('265', '323'),\n",
              "  ('1795', '1935'),\n",
              "  ('149', '157'),\n",
              "  ('1069', '1091'),\n",
              "  ('1334', '1462'),\n",
              "  ('1577', '1616'),\n",
              "  ('2023', '2086')],\n",
              " 'Next plague outbreak in Madagascar could be \\'stronger\\': WHO Geneva - The World Health Organisation chief on Wednesday said a deadly plague epidemic appeared to have been brought under control in Madagascar, but warned the next outbreak would likely be stronger. \"The next transmission could be more pronounced or stronger,\" WHO Director-General Tedros Adhanom Ghebreyesus told reporters in Geneva, insisting that \"the issue is serious.\" An outbreak of both bubonic plague, which is spread by infected rats via flea bites, and pneumonic plague, spread person to person, has killed more than 200 people in the Indian Ocean island nation since August. Madagascar has suffered bubonic plague outbreaks almost every year since 1980, often caused by rats fleeing forest fires. The disease tends to make a comeback each hot rainy season, from September to April. On average, between 300 and 600 infections are recorded every year among a population approaching 25 million people, according to a UN estimate. But Tedros voiced alarm that \"plague in Madagascar behaved in a very, very different way this year.\" Cases sprang up far earlier than usual and, instead of being confined to the countryside, the disease infiltrated towns. The authorities recorded more than 2 000 cases, and Tedros said Wednesday the death toll stood at 207. He also pointed to the presence of the pneumonic version, which spreads more easily and is more virulent, in the latest outbreak. He praised the rapid response from WHO and Madagascar authorities that helped bring the outbreak under control, but warned that the danger was not over. The larger-than-usual outbreak had helped spread the bacteria that causes the plague more widely. This along with poor sanitation and vector control on Madagascar meant that \"when (the plague) comes again it starts from more stock, and the magnitude in the next transmission could be higher than the one that we saw,\" Tedros said. \"That means that Madagascar could be affected more, and not only that, it could even spill over into neighbouring countries and beyond,\" he warned. Complicating vector control is the fact that the fleas that carry the Yersinia pestis bacteria that causes the plague have proven to be widely resistant to chemicals and insecticides. \"That\\'s a dangerous combination,\" Tedros said.')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(columns = ['ID','text','labels'])\n",
        "count = 0\n",
        "for article in train_articles.keys():\n",
        "    train_df.loc[count,'ID'] = article\n",
        "    train_df.loc[count,'text'] = train_articles[article]\n",
        "    temp_label = [label for label in train_labels_str[article]]\n",
        "    train_df.loc[count,'labels'] = ','.join(temp_label)\n",
        "    count+=1\n",
        "del train_df['ID']"
      ],
      "metadata": {
        "id": "gnYSkHnFKKAk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xuZtyEikLKSg",
        "outputId": "d49e6784-2454-43f7-9c12-fc4de9f17c69"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  \\\n",
              "0    Next plague outbreak in Madagascar could be 's...   \n",
              "1    US bloggers banned from entering UK Two promin...   \n",
              "2    Kate Steinle's death at the hands of a Mexican...   \n",
              "3    U.S. judge frees Indonesian immigrant held by ...   \n",
              "4    Here are all the sexual misconduct accusations...   \n",
              "..                                                 ...   \n",
              "366  Altered Election Documents Tied To Florida Dem...   \n",
              "367  Migrant Caravan Reach Border & Climb Atop Fenc...   \n",
              "368  Guardian ups its vilification of Julian Assang...   \n",
              "369  This Guardian Fake News Story Proves That The ...   \n",
              "370  SNL Indian Comedian Silenced for \"Offensive Jo...   \n",
              "\n",
              "                                                labels  \n",
              "0    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "1    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "2    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "3    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "4    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "..                                                 ...  \n",
              "366  O,O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,O...  \n",
              "367  O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,...  \n",
              "368  O,O,O,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
              "369  I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Pr...  \n",
              "370  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "\n",
              "[371 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4eee349-ef12-4fca-946f-e89e6c241d4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Next plague outbreak in Madagascar could be 's...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US bloggers banned from entering UK Two promin...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kate Steinle's death at the hands of a Mexican...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U.S. judge frees Indonesian immigrant held by ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Here are all the sexual misconduct accusations...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>Altered Election Documents Tied To Florida Dem...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>Migrant Caravan Reach Border &amp; Climb Atop Fenc...</td>\n",
              "      <td>O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>Guardian ups its vilification of Julian Assang...</td>\n",
              "      <td>O,O,O,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>This Guardian Fake News Story Proves That The ...</td>\n",
              "      <td>I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>SNL Indian Comedian Silenced for \"Offensive Jo...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>371 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4eee349-ef12-4fca-946f-e89e6c241d4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4eee349-ef12-4fca-946f-e89e6c241d4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4eee349-ef12-4fca-946f-e89e6c241d4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train_df.loc[20,'text'].split(' '))"
      ],
      "metadata": {
        "id": "Fa3vCiX9sMei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df.text[0].strip().split(' ')))\n",
        "train_df.text[0], train_df.labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgWP0eY-VVlY",
        "outputId": "ebbd84b5-ceb1-48bc-e8be-108fef800f69"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Next plague outbreak in Madagascar could be \\'stronger\\': WHO Geneva - The World Health Organisation chief on Wednesday said a deadly plague epidemic appeared to have been brought under control in Madagascar, but warned the next outbreak would likely be stronger. \"The next transmission could be more pronounced or stronger,\" WHO Director-General Tedros Adhanom Ghebreyesus told reporters in Geneva, insisting that \"the issue is serious.\" An outbreak of both bubonic plague, which is spread by infected rats via flea bites, and pneumonic plague, spread person to person, has killed more than 200 people in the Indian Ocean island nation since August. Madagascar has suffered bubonic plague outbreaks almost every year since 1980, often caused by rats fleeing forest fires. The disease tends to make a comeback each hot rainy season, from September to April. On average, between 300 and 600 infections are recorded every year among a population approaching 25 million people, according to a UN estimate. But Tedros voiced alarm that \"plague in Madagascar behaved in a very, very different way this year.\" Cases sprang up far earlier than usual and, instead of being confined to the countryside, the disease infiltrated towns. The authorities recorded more than 2 000 cases, and Tedros said Wednesday the death toll stood at 207. He also pointed to the presence of the pneumonic version, which spreads more easily and is more virulent, in the latest outbreak. He praised the rapid response from WHO and Madagascar authorities that helped bring the outbreak under control, but warned that the danger was not over. The larger-than-usual outbreak had helped spread the bacteria that causes the plague more widely. This along with poor sanitation and vector control on Madagascar meant that \"when (the plague) comes again it starts from more stock, and the magnitude in the next transmission could be higher than the one that we saw,\" Tedros said. \"That means that Madagascar could be affected more, and not only that, it could even spill over into neighbouring countries and beyond,\" he warned. Complicating vector control is the fact that the fleas that carry the Yersinia pestis bacteria that causes the plague have proven to be widely resistant to chemicals and insecticides. \"That\\'s a dangerous combination,\" Tedros said.',\n",
              " 'O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df.labels[0].split(','))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ6wH7eYVYnI",
        "outputId": "bfdce65f-76c7-4832-d71a-06131c1f5cc5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "371"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.mean([len(train_df.loc[i,'text'].split(' ')) for i in range(len(train_df))])"
      ],
      "metadata": {
        "id": "4yzjYbMLLuaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_to_ids = {k: v for v, k in enumerate(['B-Prop','I-Prop', 'O'])}\n",
        "# ids_to_labels = {v: k for v, k in enumerate(['B-Prop','I-Prop', 'O'])}\n",
        "# labels_to_ids, ids_to_labels\n",
        "\n",
        "labels_to_ids = {k: v for v, k in enumerate(['I-Prop', 'O'])}\n",
        "ids_to_labels = {v: k for v, k in enumerate(['I-Prop', 'O'])}\n",
        "labels_to_ids, ids_to_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ4ePHvFPP9c",
        "outputId": "2ebe9dcc-4693-4ffb-96ce-3f405b8cc06d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'I-Prop': 0, 'O': 1}, {0: 'I-Prop', 1: 'O'})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 2\n",
        "VALID_BATCH_SIZE = 2\n",
        "DEV_BATCH_SIZE = 2\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 1e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "4xZtk9jGLVoI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a2e38997a17747dc95cc95c94b7e0f2b",
            "94d0ea7ab1aa4f429580242bc7006a44",
            "c5be829e32b24ce6be48cf078092478f",
            "a525c82820904bbd9ec08036f1a9f289",
            "74277cfb536b4b51be28dcb1754ea98e",
            "7bd78e80f9884fdc8e019276d52cd99e",
            "383c45f6b2a54653957b94bf2971e4aa",
            "d5ce9d5639144559912d52cd21975fed",
            "c4fcb6c738814b3a94ea1b474049f03c",
            "fb3d67de0fc040af90c7d76590c66d06",
            "300581fd54534eeba96424ba5d0e8626"
          ]
        },
        "outputId": "8161bba2-49d5-4d60-c498-14efacd8eec9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2e38997a17747dc95cc95c94b7e0f2b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "  def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        # step 1: get the sentence and word labels \n",
        "        sentence = self.data.text[index].strip().split(' ')  \n",
        "        word_labels = self.data.labels[index].split(\",\") \n",
        "\n",
        "\n",
        "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
        "        encoding = self.tokenizer(sentence,\n",
        "                             is_pretokenized=True, \n",
        "                             return_offsets_mapping=True, \n",
        "                             padding='max_length', \n",
        "                             truncation=True, \n",
        "                             max_length=self.max_len)\n",
        "\n",
        "        # step 3: create token labels only for first word pieces of each tokenized word\n",
        "        labels = [labels_to_ids[label] for label in word_labels] \n",
        "\n",
        "        # create an empty array of -100 of length max_length\n",
        "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
        "        i = 0\n",
        "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
        "          if mapping[0] == 0 and mapping[1] != 0:\n",
        "            # overwrite label\n",
        "            encoded_labels[idx] = labels[i]\n",
        "            i += 1\n",
        "\n",
        "        # step 4: turn everything into PyTorch tensors\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.as_tensor(encoded_labels)\n",
        "        \n",
        "        return item\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "Cn_W5QbwMaMq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 1\n",
        "train_dataset = train_df.sample(frac=train_size,random_state=200)\n",
        "test_dataset = train_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(train_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EifAo7mAMogL",
        "outputId": "ec8096bb-e724-4fdd-f3c3-c26863d47a79"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (371, 2)\n",
            "TRAIN Dataset: (371, 2)\n",
            "TEST Dataset: (0, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(training_set[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04_uth-tOC1x",
        "outputId": "7bd00228-2b7a-48cd-e429-63a5c01e6bb7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'input_ids': tensor([  101,  5152,  3003,  4455,  2005,  9187,  1997,  1523,  2637,  1010,\n",
              "          3725,  1010,  3607,  1010,  2605,  1010,  1998,  3304,  1524,  3728,\n",
              "          1037,  5152, 14056,  1999, 13437,  2315,  2056,  1047,  5369,  7507,\n",
              "         28578,  1010,  2040,  2003,  6989,  2007,  1996,  2248,  4013,  1011,\n",
              "         21146,  4360,  1010,  4013,  1011, 28034,  3029,  7632,  2480,  2497,\n",
              "         21183,  1011, 11937, 26378,  2099,  1010,  4161,  1006,  2000, 15936,\n",
              "         11652,  1997,  1523, 16455,  2226, 20730,  1524,  2013,  2010,  4378,\n",
              "          1007,  1010,  2008,  1996,  1523,  5069,  1997,  2019,  5499,  2110,\n",
              "          1529,  5942,  1996,  9187,  1997,  2637,  1010,  3725,  1010,  3607,\n",
              "          1010,  2605,  1010,  1998,  3304,  1516,  4199,  1998,  2060,  1999,\n",
              "         20740,  2140,  4915,  2097,  2022, 11438,  1010, 16455,  5627,  1012,\n",
              "          1524,  2429,  2000,  1996,  2690,  2264,  2865,  2470,  2820,  1006,\n",
              "          2033,  2213,  3089,  1007,  1010,  1047,  5369,  7507, 28578,  2036,\n",
              "          2056,  1024,  1523,  2044,  1996,  4277,  1997, 16455,  2020,  4704,\n",
              "          1010,  1998,  1996,  2182,  4588, 25228,  2020,  9770,  2006,  1996,\n",
              "          7486,  1010,  1996,  2087,  2590,  2518,  2000,  2079,  2003,  2000,\n",
              "          9239,  1996,  3627,  1997,  1996,  7486,  1010,  2083,  1996, 21288,\n",
              "          1998,  1996,  3103,  2532,  1010,  1999,  2344,  2000, 20687,  5499,\n",
              "          2166,  1998,  2000,  8116,  1996,  5499,  4471,  2000,  1996,  2088,\n",
              "          1012,  2026,  3428,  1010,  1996, 25323,  1997,  2023,  2651,  2323,\n",
              "          2022,  1996,  5069,  1997,  2019,  5499,  2110,  2058,  2035,  1996,\n",
              "          4915,  1997,  1996,  7486,  1012,  1524,  2202,  2256,  8554,  1011,\n",
              "          2466,  4247,  2917,  2097, 12049, 10556, 27313,  8953,  2022,  4484,\n",
              "          2000,  1996,  4259,  2457,  1029,  2097, 12049, 10556, 27313,  8953,\n",
              "          2022,  4484,  2000,  1996,  4259,  2457,  1029,  2097, 12049, 10556,\n",
              "         27313,  8953,  2022,  4484,  2000,  1996,  4259,  2457,  1029,  1008,\n",
              "          2748,  1010,  2002,  2097,  2022,  4484,  1012,  2053,  1010,  2002,\n",
              "          2097,  2025,  2022,  4484,  1012, 10373,  1008, 10373,  2023,  2492,\n",
              "          2003,  2005, 27354,  5682,  1998,  2323,  2022,  2187, 15704,  1012,\n",
              "          7678,  2023,  8554,  8624,  2017,  3229,  2000,  4071, 21080, 14409,\n",
              "          2489,  1997,  3715,  1012,  2017,  2089, 23569,  2041,  2012, 15933,\n",
              "          1012,  2017,  2036,  5993,  2000,  2023,  2609,  1005,  1055,  9394,\n",
              "          3343,  1998,  3408,  1997,  2224,  1012,  1998,  2053,  2655,  2000,\n",
              "          9239,  1996, 28034,  2052,  2022,  3143,  2302,  1037, 25430, 15457,\n",
              "          2012,  1996,  5181,  1010,  3183,  1996, 23183,  1521,  2019, 24414,\n",
              "          2015,  1006,  1019,  1024,  6445,  1007,  1996,  5409,  6716,  1997,\n",
              "          1996,  7486,  1012,  1047,  5369,  7507, 28578, 10173,  2008,  1523,\n",
              "          2023,  2097,  4148,  1010,  1997,  2607,  1010,  2044,  1996,  9614,\n",
              "          1997,  1996, 18294,  3644,  9178,  1010,  1998,  2044,  7931,  1997,\n",
              "          1996,  4915,  2104,  3622, 18962,  1010,  2066, 13329,  1998,  2500,\n",
              "          1012,  1524,  2065,  2056,  1047,  5369,  7507, 28578,  2020,  1037,\n",
              "          2512,  1011,  5152,  3038,  2008,  7486,  2734,  2000,  6033,  1523,\n",
              "          1996, 18294,  3644,  9178,  1524,  1998, 16152,  2637,  1010,  3725,\n",
              "          1010,  3607,  1010,  2605,  1010,  1998,  3304,  1010,  2002,  2052,\n",
              "          2022,  5496,  1997,  1523,  7025,  7361,  6806, 11607,  1524,  1998,\n",
              "          1523,  2502,  4140,  2854,  1012,  1524,  2021,  2053,  2028,  2097,\n",
              "          2202,  2151,  3327,  5060,  1997,  2023,  1012,  2027,  2323,  1010,\n",
              "          2174,  1012,  1047,  5369,  7507, 28578,  2003,  2025,  2070,  3972,\n",
              "         13936,  5470, 12070, 16806,  3070,  2006,  1037, 22946,  2395,  3420,\n",
              "          1012,  2002,  2001,  4092,  2012,  7632,  2480,  2497, 21183,  1011,\n",
              "         11937, 26378,  2099,  1521,  1055,  2248, 28034,  3034,  1025,  2348,\n",
              "          7632,   102]),\n",
              " 'labels': tensor([-100,    1,    1,    1,    1,    1,    1,    1, -100, -100,    1, -100,\n",
              "            1, -100,    1, -100,    1,    1, -100,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1, -100, -100, -100, -100,    1,    1,    1,    1,\n",
              "            1,    1,    1, -100, -100, -100, -100,    1, -100, -100,    1,    1,\n",
              "         -100, -100,    1, -100, -100, -100, -100, -100,    1,    1, -100,    1,\n",
              "            0,    0,    0, -100, -100,    0, -100,    1,    1,    1, -100, -100,\n",
              "            1,    1,    0, -100,    0,    0,    0,    0, -100, -100,    0,    0,\n",
              "            0,    0, -100,    0, -100,    0, -100,    0, -100,    0,    0,    0,\n",
              "            0,    0,    0,    0, -100, -100,    0,    0,    0,    0, -100,    1,\n",
              "            0, -100, -100,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "         -100, -100, -100, -100, -100,    1, -100, -100, -100,    1,    1, -100,\n",
              "            1, -100,    0,    0,    0,    0,    0,    0, -100,    0,    0,    0,\n",
              "         -100,    0,    0,    0,    0,    0,    0, -100,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100,    0,\n",
              "            0,    0,    0,    0,    0, -100, -100,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100,    0,\n",
              "            0, -100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1, -100, -100,\n",
              "            1,    1,    1,    1,    1,    1, -100,    1,    1,    1, -100, -100,\n",
              "            1,    1,    1,    1,    1,    1, -100,    1,    1,    1, -100, -100,\n",
              "            1,    1,    1,    1,    1,    1, -100,    1,    1, -100,    1,    1,\n",
              "            1,    1, -100,    1, -100,    1,    1,    1,    1,    1, -100,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1, -100,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1, -100,    1,    1,    1,    1,    1,    1, -100,    1,\n",
              "            1,    1,    1,    1,    1, -100, -100,    1,    1,    1,    1,    1,\n",
              "            1, -100,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1, -100,    0,    0,    0, -100,    0,    1,    1, -100,\n",
              "         -100,    1, -100,    1, -100, -100, -100, -100,    1,    1,    0,    0,\n",
              "            0,    0, -100,    0, -100, -100, -100,    1,    1,    1, -100,    1,\n",
              "            1, -100,    1,    1, -100,    1,    1,    0,    0,    0,    0,    0,\n",
              "            0, -100,    0,    1,    1,    1,    1,    1,    1,    1,    1, -100,\n",
              "            1,    1,    1,    1, -100, -100,    1,    1,    1, -100, -100, -100,\n",
              "            1,    1,    1, -100, -100,    1,    1,    1,    1,    1,    1,    1,\n",
              "         -100,    1,    1,    1, -100,    1,    1,    1, -100,    1, -100,    1,\n",
              "         -100,    1, -100,    1,    1, -100,    1,    1,    1,    1,    1,    1,\n",
              "         -100, -100, -100, -100, -100,    1,    1, -100, -100, -100, -100, -100,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1, -100,    1,\n",
              "            1, -100,    1, -100,    1, -100, -100, -100,    1,    1,    1,    1,\n",
              "         -100,    1, -100,    1, -100,    1,    1,    1,    1,    1, -100,    1,\n",
              "            1,    1,    1,    1, -100, -100,    1, -100, -100, -100, -100, -100,\n",
              "         -100,    1,    1,    1, -100,    1,    1, -100]),\n",
              " 'offset_mapping': tensor([[0, 0],\n",
              "         [0, 6],\n",
              "         [0, 6],\n",
              "         ...,\n",
              "         [0, 8],\n",
              "         [0, 2],\n",
              "         [0, 0]]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token, mapping, label in zip(tokenizer.convert_ids_to_tokens(training_set[1][\"input_ids\"]), training_set[1]['offset_mapping'], training_set[1][\"labels\"]):\n",
        "  print('{0:10} {1}'.format(token, label), '  ', mapping)"
      ],
      "metadata": {
        "id": "qtLQ091b4Gpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "# testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "lt-Hx7yvM4K0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d6e8cb3fbb314a5582a93bf83d6f9f5d",
            "995f4496249644568cf545b768cd1ad0",
            "e28fa0abf2364d3bb72f32dc57ce341a",
            "965af4515922439b8fec3b4fc633f62f",
            "fc42aea8d70946078cee1c0fc429f9db",
            "f06050eae2424f92a43040fa0566c1e4",
            "302193092e47432aa5b76c1ec00e571f",
            "39cc5e2ae0514cf1a4b261217788f811",
            "c18444ba0dba493f86d3b34d6804b712",
            "1aefb9a3ee1e419e8f6f5a8d1adccdb0",
            "217a363439f94dbda519e5d9b4d8d5d7",
            "bbf99f8ae0714f888e667b308fbdeb16",
            "18da7189057844e08b81ce1c98fed3f5",
            "141b4dd609074d95bff4bbb6a80cda0f",
            "abb2d93484c04b3eafb2ffc3c8f9cb3b",
            "f5c488bef56441c585606d646ec0a963",
            "cad6af4dc11f44508fb8b7a3ff089e12",
            "4cbd80dbeb8145f89aec1bbfe0736e37",
            "069e96cd98a34eb7a63b6febcba59589",
            "2bb18647f61e4457a0b18c7bb137eaa9",
            "392b9b695a694a8d8ee7ef0aeee3008b",
            "709e71e0c3434078b49c1c680352f5ec"
          ]
        },
        "id": "KKmKQIn9M89Q",
        "outputId": "ae0ae8a7-d11e-414d-805f-589d20f6c999"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6e8cb3fbb314a5582a93bf83d6f9f5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbf99f8ae0714f888e667b308fbdeb16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = training_set[2]\n",
        "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
        "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
        "labels = inputs[\"labels\"].unsqueeze(0)\n",
        "\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5P2SDc5M-cl",
        "outputId": "f7be2178-6e2c-4961-819a-03c25c139222"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6812, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmsTVYguXyXC",
        "outputId": "2f8ea044-49e0-4ae6-b9f3-d128083d4c31"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "id": "XccWGsGWWSrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdfe431-0693-4d74-d3ec-9a243b942da4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ],
      "metadata": {
        "id": "kUhxv8JbS4ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f0a26c-d0e8-4c5c-f627-f858271116d2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "JQ7VzuqrVMuw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        \n",
        "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "        labels = batch['labels'].to(device, dtype = torch.long)\n",
        "\n",
        "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += labels.size(0)\n",
        "        \n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "           \n",
        "        # compute training accuracy\n",
        "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        \n",
        "        # only compute accuracy at active labels\n",
        "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
        "        \n",
        "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "        \n",
        "        tr_labels.extend(labels)\n",
        "        tr_preds.extend(predictions)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "    \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "        \n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ],
      "metadata": {
        "id": "3urEiVB8VU-t"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "rOtLvgsvChES"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "id": "aqAS88OlVWG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_labels[-100] = 'O'"
      ],
      "metadata": {
        "id": "96yRogjPqlG-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            labels = batch['labels'].to(device, dtype = torch.long)\n",
        "            # temp_labels = labels\n",
        "            # print(idx,labels)\n",
        "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += labels.size(0)\n",
        "        \n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            \n",
        "            # only compute accuracy at active labels\n",
        "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            # print(temp_labels == labels)\n",
        "\n",
        "            eval_labels.extend(labels)\n",
        "            eval_preds.extend(predictions)\n",
        "            # eval_labels.extend(flattened_targets)\n",
        "            # eval_preds.extend(flattened_predictions)\n",
        "            \n",
        "            # tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
        "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "metadata": {
        "id": "eVEy7H9xVYPS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_annotation = load_annotation_list_from_folder(dev_labels_file, techniques_names)\n",
        "dev_labels = {}\n",
        "for article in dev_articles.keys():\n",
        "    labels = [0] * len(dev_articles[article])\n",
        "    for annot in dev_annotation[article]:\n",
        "        labels[int(annot[0]):int(annot[1])] = [1] * (int(annot[1]) - int(annot[0]))\n",
        "    dev_labels[article] = labels\n",
        "\n",
        "dev_labels_str = {}\n",
        "for article in dev_articles.keys():\n",
        "    labels = [0] * len(dev_articles[article].split(' '))\n",
        "\n",
        "    index = 0\n",
        "    \n",
        "    word_index = -1\n",
        "    for word in dev_articles[article].split(' '):\n",
        "      word_index+=1\n",
        "      if (index<len(dev_labels[article])) and (dev_labels[article][index] == 1):\n",
        "        labels[word_index] = 1\n",
        "      index+= len(word) + 1\n",
        "\n",
        "    str_labels = []\n",
        "    span_started = False\n",
        "    for label in labels:\n",
        "      if label == 0:\n",
        "        str_labels.append('O')\n",
        "        span_started = False\n",
        "      elif label == 1 and not span_started:\n",
        "        str_labels.append('I-Prop')\n",
        "        span_started = True\n",
        "      elif label == 1 and span_started:\n",
        "        str_labels.append('I-Prop')\n",
        "        span_started = True\n",
        "\n",
        "    dev_labels[article] = labels\n",
        "    dev_labels_str[article] = str_labels\n",
        "\n",
        "dev_df = pd.DataFrame(columns = ['ID','text','labels'])\n",
        "count = 0\n",
        "for article in dev_articles.keys():\n",
        "    dev_df.loc[count,'ID'] = article\n",
        "    dev_df.loc[count,'text'] = dev_articles[article]\n",
        "    # temp_label = [str(int) for int in dev_labels[article]]\n",
        "    temp_label = [label for label in dev_labels_str[article]]\n",
        "    dev_df.loc[count,'labels'] = ','.join(temp_label)\n",
        "    count+=1\n",
        "\n",
        "dev_id = dev_df['ID']\n",
        "del dev_df['ID']"
      ],
      "metadata": {
        "id": "yQzeCsx7tEWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dev_df.loc[1,'text']"
      ],
      "metadata": {
        "id": "7DfWjPrz5VrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dev_df.loc[1,'text'][1370:1393]"
      ],
      "metadata": {
        "id": "ZGtUIwrK5ZAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dev_df.loc[1,'text'].split(' ').index('American')"
      ],
      "metadata": {
        "id": "UGMsGI9A5jw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dev_df.loc[1,'labels'].split(',')[222]"
      ],
      "metadata": {
        "id": "wQNtAoY2BnbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dev_df.loc[1,'text'].split(' ')))\n",
        "print(len(dev_df.loc[1,'labels'].split(\",\")))\n",
        "dev_dataset = pd.DataFrame(dev_df.loc[0])\n",
        "data_updated = pd.DataFrame(columns = ['text','labels'])\n",
        "data_updated.loc[0, 'text'] = dev_df.loc[1].text\n",
        "data_updated.loc[0, 'labels'] = dev_df.loc[1].labels\n",
        "\n",
        "data_updated\n",
        "[i for i in range(5)]"
      ],
      "metadata": {
        "id": "mJIRNvMKdO5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#All data in dev set\n",
        "dev_dataset = dev_df\n",
        "\n",
        "dev_set = dataset(dev_dataset, tokenizer, MAX_LEN)\n",
        "dev_params = {'batch_size': DEV_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "\n",
        "dev_loader = DataLoader(dev_set, **dev_params)"
      ],
      "metadata": {
        "id": "BBU-DskwfoyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run 1 by 1\n",
        "prediction_map = {}\n",
        "actual_labels_map = {}\n",
        "\n",
        "for i in range(len(dev_df)):\n",
        "    single_dev_row = pd.DataFrame(columns = ['text','labels'])\n",
        "    single_dev_row.loc[0, 'text'] = dev_df.loc[i].text\n",
        "    single_dev_row.loc[0, 'labels'] = dev_df.loc[i].labels\n",
        "\n",
        "    dev_set = dataset(single_dev_row, tokenizer, MAX_LEN)\n",
        "    dev_loader = DataLoader(dev_set, **dev_params)\n",
        "    labels, predictions = valid(model, dev_loader)\n",
        "    prediction_map[dev_id[i]] = predictions\n",
        "    actual_labels_map[dev_id[i]] = labels"
      ],
      "metadata": {
        "id": "oPT_hwe_y9XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_actual, predictions = valid(model, dev_loader)"
      ],
      "metadata": {
        "id": "LV29UG52tu6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_word_len = []\n",
        "for article in dev_df.text:\n",
        "    total_word_len.append(len(article.split(' ')))\n",
        "np.mean(total_word_len), len(dev_df.text)\n"
      ],
      "metadata": {
        "id": "quAwl4AWCyEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.count('I-Prop'), predictions.count('B-Prop'), predictions.count('O'), len(predictions)"
      ],
      "metadata": {
        "id": "hlWxIsqpBp8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_word_prediction = 0\n",
        "for index in range(len(labels)):\n",
        "  if labels[index] == predictions[index] and labels[index] is not 'O':\n",
        "    correct_word_prediction+=1\n",
        "    print(index, labels[index])\n",
        "\n",
        "print(correct_word_prediction)"
      ],
      "metadata": {
        "id": "lL8HwGRGBvk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_SI_output_file = '/content/drive/MyDrive/NLP/project_5_data/baseline-output-SI.txt'"
      ],
      "metadata": {
        "id": "vEB9WtzxDfql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(task_SI_output_file, \"w\") as fout:\n",
        "\n",
        "    for dev_article_id in dev_id:\n",
        "      article = dev_articles[dev_article_id]\n",
        "      predictions = prediction_map[dev_article_id]\n",
        "      # print(\"predictions: \", predictions)\n",
        "      labels = [0] * len(predictions)\n",
        "      for i in range(len(predictions)):\n",
        "        if predictions[i] == 'B-Prop' or predictions[i] == 'I-Prop':\n",
        "          labels[i] = 1\n",
        "        else:\n",
        "          labels[i] = 0\n",
        "      \n",
        "    #   print(\"Labels: \", labels)\n",
        "    #   if 1 in labels:\n",
        "    #     print(labels.count(1))\n",
        "    #   print(\"Article: \", article)\n",
        "    #   print(len(article))\n",
        "\n",
        "      char_index = 0\n",
        "      span_started = False\n",
        "      span_len = 0\n",
        "      start = 0\n",
        "      label_index = 0\n",
        "      for idx in range(len(article)):\n",
        "        if article[idx] == ' ' and span_started:\n",
        "          label_index += 1\n",
        "          span_len += 1\n",
        "          continue\n",
        "        elif article[idx] == ' ':\n",
        "          label_index += 1\n",
        "          continue\n",
        "        if label_index >= len(labels):\n",
        "          break\n",
        "        if labels[label_index] == 1 and not span_started:\n",
        "          span_started = True          \n",
        "          start = idx\n",
        "          span_len += 1 \n",
        "        elif labels[label_index] == 1 and span_started:        \n",
        "          span_len += 1           \n",
        "        elif labels[label_index] == 0 and span_started:\n",
        "          span_started = False          \n",
        "          if span_len > 0:\n",
        "            fout.write(\"%s\\t%s\\t%s\\n\" % (dev_article_id, start, start+span_len))\n",
        "            print(dev_article_id, start, start+span_len)\n",
        "            span_len = 0\n",
        "\n",
        "      print(label_index)\n",
        "            "
      ],
      "metadata": {
        "id": "5FqPMj7LlrVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77adde1e-522d-4b92-de80-baa4fa9a2f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288\n",
            "730093263 1375 1384\n",
            "730093263 2062 2067\n",
            "730093263 2072 2102\n",
            "396\n",
            "730246508 1659 1676\n",
            "730246508 1693 1702\n",
            "730246508 1705 1711\n",
            "730246508 1775 1779\n",
            "730246508 1785 1794\n",
            "730246508 1810 1818\n",
            "385\n",
            "140\n",
            "738028498 0 33\n",
            "738028498 165 169\n",
            "738028498 174 177\n",
            "738028498 186 198\n",
            "738028498 201 207\n",
            "738028498 323 328\n",
            "738028498 344 350\n",
            "738028498 363 370\n",
            "738028498 587 590\n",
            "738028498 613 637\n",
            "738028498 695 739\n",
            "738028498 962 969\n",
            "738028498 995 1002\n",
            "738028498 1014 1052\n",
            "738028498 1060 1120\n",
            "738028498 1126 1129\n",
            "738028498 1133 1255\n",
            "738028498 1399 1468\n",
            "738028498 1504 1535\n",
            "738028498 1537 1553\n",
            "738028498 1567 1592\n",
            "738028498 1922 1949\n",
            "738028498 1968 1986\n",
            "738028498 2267 2281\n",
            "392\n",
            "738361208 991 1039\n",
            "738361208 1090 1095\n",
            "374\n",
            "738442776 1330 1368\n",
            "738442776 1690 1805\n",
            "738442776 1856 1878\n",
            "738442776 2113 2133\n",
            "738442776 2149 2206\n",
            "738442776 2228 2236\n",
            "738442776 2268 2272\n",
            "371\n",
            "738447109 420 509\n",
            "738447109 1904 1919\n",
            "738447109 1927 1943\n",
            "405\n",
            "320\n",
            "389\n",
            "740235127 477 484\n",
            "740235127 703 716\n",
            "740235127 752 758\n",
            "740235127 768 783\n",
            "740235127 816 821\n",
            "740235127 1191 1238\n",
            "740235127 1475 1494\n",
            "740235127 1539 1552\n",
            "740235127 1566 1662\n",
            "740235127 1693 1721\n",
            "740235127 1753 1785\n",
            "740235127 2009 2121\n",
            "381\n",
            "761568202 31 38\n",
            "761568202 310 324\n",
            "761568202 542 553\n",
            "761568202 558 597\n",
            "761568202 645 649\n",
            "761568202 653 681\n",
            "761568202 835 842\n",
            "761568202 1329 1334\n",
            "761568202 1337 1353\n",
            "761568202 1904 1912\n",
            "350\n",
            "761575506 937 986\n",
            "761575506 1005 1021\n",
            "761575506 1024 1078\n",
            "761575506 1080 1096\n",
            "761575506 1108 1113\n",
            "761575506 1127 1135\n",
            "761575506 1206 1232\n",
            "400\n",
            "761722669 591 601\n",
            "761722669 608 619\n",
            "761722669 728 745\n",
            "761722669 971 978\n",
            "761722669 982 999\n",
            "761722669 1398 1414\n",
            "761722669 1530 1593\n",
            "761722669 1848 1862\n",
            "387\n",
            "761955563 167 212\n",
            "431\n",
            "763114850 18 43\n",
            "763114850 61 95\n",
            "763114850 208 262\n",
            "763114850 265 290\n",
            "763114850 393 420\n",
            "763114850 2191 2203\n",
            "763114850 2264 2271\n",
            "763114850 2283 2287\n",
            "763114850 2302 2313\n",
            "398\n",
            "763280007 284 298\n",
            "763280007 322 433\n",
            "763280007 440 501\n",
            "763280007 512 521\n",
            "763280007 576 587\n",
            "763280007 590 618\n",
            "763280007 621 636\n",
            "763280007 1063 1101\n",
            "763280007 1128 1133\n",
            "763280007 1181 1200\n",
            "763280007 1209 1227\n",
            "763280007 1513 1532\n",
            "763280007 1545 1569\n",
            "763280007 1578 1593\n",
            "763280007 1640 1644\n",
            "763280007 1650 1659\n",
            "763280007 1666 1675\n",
            "763280007 1883 1945\n",
            "763280007 1949 1996\n",
            "763280007 2003 2016\n",
            "763280007 2023 2045\n",
            "763280007 2051 2134\n",
            "763280007 2185 2217\n",
            "763280007 2300 2303\n",
            "391\n",
            "763412406 189 192\n",
            "763412406 202 241\n",
            "763412406 257 275\n",
            "763412406 2230 2283\n",
            "378\n",
            "772836731 21 30\n",
            "772836731 104 108\n",
            "772836731 202 244\n",
            "772836731 256 264\n",
            "772836731 268 294\n",
            "772836731 726 739\n",
            "772836731 779 796\n",
            "772836731 803 832\n",
            "772836731 843 863\n",
            "772836731 866 905\n",
            "772836731 908 1097\n",
            "772836731 1221 1253\n",
            "772836731 1427 1472\n",
            "772836731 1647 1669\n",
            "772836731 1934 1950\n",
            "772836731 1977 1990\n",
            "772836731 2153 2202\n",
            "772836731 2267 2285\n",
            "389\n",
            "773650987 1222 1238\n",
            "773650987 1442 1454\n",
            "773650987 1457 1488\n",
            "773650987 1781 1804\n",
            "773650987 1810 1834\n",
            "773650987 1840 1860\n",
            "773650987 2451 2533\n",
            "773650987 2541 2556\n",
            "394\n",
            "776126299 2304 2310\n",
            "422\n",
            "776385494 24 29\n",
            "776385494 539 565\n",
            "776385494 1097 1118\n",
            "776385494 1406 1471\n",
            "776385494 1593 1603\n",
            "383\n",
            "777720051 532 576\n",
            "777720051 1201 1209\n",
            "777720051 1239 1242\n",
            "777720051 1256 1279\n",
            "777720051 1284 1317\n",
            "366\n",
            "407\n",
            "777869943 540 552\n",
            "777869943 703 780\n",
            "777869943 970 988\n",
            "777869943 1062 1078\n",
            "777869943 1754 1765\n",
            "412\n",
            "778094905 374 397\n",
            "778094905 408 411\n",
            "778094905 417 421\n",
            "398\n",
            "403\n",
            "778507244 162 182\n",
            "778507244 1735 1768\n",
            "373\n",
            "778730964 91 103\n",
            "778730964 200 214\n",
            "778730964 261 267\n",
            "778730964 378 402\n",
            "778730964 539 635\n",
            "402\n",
            "779309765 0 14\n",
            "779309765 168 179\n",
            "779309765 409 475\n",
            "779309765 630 652\n",
            "779309765 1518 1542\n",
            "779309765 1578 1582\n",
            "779309765 1691 1696\n",
            "779309765 1707 1743\n",
            "779309765 2029 2033\n",
            "779309765 2266 2282\n",
            "398\n",
            "781672902 325 333\n",
            "781672902 439 447\n",
            "781672902 472 508\n",
            "781672902 1486 1507\n",
            "781672902 1545 1548\n",
            "385\n",
            "782149032 376 386\n",
            "292\n",
            "782448403 763 797\n",
            "782448403 859 862\n",
            "782448403 898 995\n",
            "782448403 1029 1093\n",
            "782448403 1399 1411\n",
            "782448403 1442 1449\n",
            "782448403 1762 1804\n",
            "782448403 1860 1908\n",
            "782448403 1914 1920\n",
            "363\n",
            "396\n",
            "784143418 68 77\n",
            "784143418 86 100\n",
            "784143418 103 120\n",
            "784143418 158 187\n",
            "378\n",
            "784382409 0 79\n",
            "404\n",
            "785331076 117 166\n",
            "422\n",
            "420\n",
            "787085939 411 467\n",
            "787085939 901 915\n",
            "787085939 920 1060\n",
            "787085939 1973 1988\n",
            "404\n",
            "787730392 48 95\n",
            "787730392 137 149\n",
            "787730392 161 166\n",
            "787730392 172 177\n",
            "787730392 324 335\n",
            "787730392 371 384\n",
            "787730392 390 409\n",
            "787730392 676 718\n",
            "787730392 1714 1724\n",
            "787730392 1728 1740\n",
            "402\n",
            "787966255 75 81\n",
            "787966255 462 473\n",
            "379\n",
            "788271400 4 20\n",
            "788271400 115 158\n",
            "788271400 258 267\n",
            "788271400 279 298\n",
            "788271400 756 761\n",
            "788271400 807 1035\n",
            "788271400 2000 2017\n",
            "376\n",
            "788273361 58 77\n",
            "788273361 168 182\n",
            "788273361 194 229\n",
            "788273361 1195 1224\n",
            "788273361 1236 1245\n",
            "400\n",
            "788626289 600 616\n",
            "788626289 668 717\n",
            "788626289 722 757\n",
            "396\n",
            "788847916 639 662\n",
            "420\n",
            "789454337 252 263\n",
            "789454337 973 1012\n",
            "420\n",
            "789512681 161 176\n",
            "406\n",
            "403\n",
            "401\n",
            "790666929 43 56\n",
            "790666929 2075 2235\n",
            "386\n",
            "794141509 32 69\n",
            "794141509 89 97\n",
            "794141509 313 383\n",
            "794141509 405 410\n",
            "794141509 428 435\n",
            "794141509 442 479\n",
            "794141509 495 601\n",
            "394\n",
            "794344513 136 143\n",
            "794344513 156 227\n",
            "794344513 317 330\n",
            "794344513 1415 1437\n",
            "794344513 1448 1458\n",
            "794344513 1466 1487\n",
            "794344513 1526 1627\n",
            "794344513 1635 1640\n",
            "794344513 1645 1662\n",
            "379\n",
            "798244842 43 76\n",
            "798244842 81 104\n",
            "798244842 256 293\n",
            "798244842 318 324\n",
            "798244842 328 339\n",
            "798244842 343 351\n",
            "798244842 546 615\n",
            "798244842 654 669\n",
            "798244842 673 754\n",
            "798244842 758 810\n",
            "798244842 1601 1633\n",
            "798244842 1682 1693\n",
            "798244842 1718 1733\n",
            "798244842 1929 1944\n",
            "798244842 2071 2079\n",
            "798244842 2085 2093\n",
            "798244842 2187 2206\n",
            "418\n",
            "832908730 1811 1818\n",
            "832908730 2228 2241\n",
            "832908730 2499 2510\n",
            "406\n",
            "832908905 1770 1809\n",
            "832908905 1926 1933\n",
            "409\n",
            "832908978 2193 2204\n",
            "832908978 2360 2415\n",
            "415\n",
            "832910505 33 38\n",
            "832910505 309 335\n",
            "832910505 931 945\n",
            "832910505 1180 1195\n",
            "832910505 1360 1378\n",
            "832910505 1404 1417\n",
            "246\n",
            "832913316 797 894\n",
            "832913316 1256 1297\n",
            "832913316 1558 1616\n",
            "832913316 1647 1661\n",
            "832913316 1721 1750\n",
            "357\n",
            "832913653 939 991\n",
            "832913653 2232 2261\n",
            "832913653 2424 2472\n",
            "409\n",
            "832916492 34 46\n",
            "832916492 282 292\n",
            "832916492 298 324\n",
            "832916492 402 414\n",
            "832916492 517 530\n",
            "832916492 812 821\n",
            "832916492 855 865\n",
            "832916492 1002 1059\n",
            "832916492 1176 1204\n",
            "302\n",
            "227\n",
            "832917532 2200 2204\n",
            "832917532 2244 2451\n",
            "389\n",
            "118\n",
            "398\n",
            "999000858 41 56\n",
            "999000858 165 178\n",
            "999000858 332 350\n",
            "999000858 371 376\n",
            "999000858 490 505\n",
            "999000858 594 617\n",
            "999000858 624 630\n",
            "999000858 1682 1696\n",
            "405\n",
            "427\n",
            "999000878 1801 1810\n",
            "411\n",
            "999001211 61 64\n",
            "999001211 70 76\n",
            "999001211 90 141\n",
            "999001211 442 454\n",
            "999001211 713 731\n",
            "999001211 739 766\n",
            "999001211 780 785\n",
            "999001211 790 805\n",
            "999001211 917 980\n",
            "999001211 2038 2044\n",
            "410\n",
            "999001256 368 376\n",
            "999001256 389 394\n",
            "999001256 405 441\n",
            "999001256 456 525\n",
            "999001256 1870 1914\n",
            "999001256 1944 1991\n",
            "999001256 2082 2122\n",
            "999001256 2157 2169\n",
            "999001256 2200 2257\n",
            "999001256 2434 2452\n",
            "413\n",
            "999001259 48 59\n",
            "999001259 87 107\n",
            "999001259 1303 1315\n",
            "999001259 2308 2312\n",
            "386\n",
            "999001280 5 37\n",
            "999001280 65 131\n",
            "999001280 195 205\n",
            "999001280 212 217\n",
            "999001280 221 227\n",
            "999001280 266 283\n",
            "999001280 351 355\n",
            "999001280 363 419\n",
            "999001280 694 700\n",
            "999001280 710 720\n",
            "999001280 905 982\n",
            "999001280 1996 2009\n",
            "348\n",
            "420\n",
            "999001299 967 994\n",
            "417\n",
            "999001323 1095 1194\n",
            "999001323 2061 2067\n",
            "405\n",
            "999001419 1107 1110\n",
            "999001419 1152 1208\n",
            "379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/NLP/\n",
        "!python3 task-SI_scorer.py -s project_5_data/baseline-output-SI.txt -r project_5_data/datasets/dev-labels-task-si/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQehQPP8---9",
        "outputId": "70c6938f-d8e8-45bb-e046-eeec4d0cde00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP\n",
            "2022-03-27 05:09:11,884 - INFO - Checking user submitted file\n",
            "2022-03-27 05:09:12,004 - INFO - Scoring the submission with precision and recall method\n",
            "2022-03-27 05:09:12,081 - INFO - Precision=145.427868/355=0.409656\tRecall=136.975633/940=0.145719\n",
            "2022-03-27 05:09:12,081 - INFO - F1=0.214970\n"
          ]
        }
      ]
    }
  ]
}