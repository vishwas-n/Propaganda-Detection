{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYb4b2dbXqY7"
   },
   "outputs": [],
   "source": [
    "#  !pip install transformers seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6yIqY1uXUyl",
    "outputId": "65052a6c-7a27-45b6-d581-7b77fe6aa1ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.1.0\n",
      "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
      "\u001b[K     |████████████████████████████████| 884 kB 5.8 MB/s \n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 37.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.21.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 42.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (21.3)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 43.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.64.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.1.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=e30848dd497c0325a0c55845890dfa7a3a3686a6776048ac5d39df0a1f1e9917\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WkJISARMfdS"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
    "from transformers import RobertaTokenizerFast, RobertaConfig, RobertaForTokenClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import cuda\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMJAleGYNglf",
    "outputId": "f23f74c3-1fbd-489b-bd81-44667ab40410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9rBtiyiXq3p",
    "outputId": "4a794361-9f36-4958-a79e-9c3e6aa9fcba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N10O1opYXyjM"
   },
   "outputs": [],
   "source": [
    "train_folder = \"/content/drive/MyDrive/NLP/project_5_data/datasets/train-articles\" \n",
    "dev_folder = \"/content/drive/MyDrive/NLP/project_5_data/datasets/dev-articles\"    \n",
    "train_labels_file = \"/content/drive/MyDrive/NLP/project_5_data/datasets/train-labels-task-si/\"\n",
    "dev_labels_file = \"/content/drive/MyDrive/NLP/project_5_data/datasets/dev-labels-task-si\"\n",
    "task_TC_output_file = \"/content/drive/MyDrive/NLP/project_5_data/baseline-output-TC.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHIyOpGKGz2r"
   },
   "outputs": [],
   "source": [
    "def read_articles_from_file_list(folder_name, file_pattern=\"*.txt\"):\n",
    "    \"\"\"\n",
    "    Read articles from files matching patterns <file_pattern> from  \n",
    "    the directory <folder_name>. \n",
    "    The content of the article is saved in the dictionary whose key\n",
    "    is the id of the article (extracted from the file name).\n",
    "    Each element of <sentence_list> is one line of the article.\n",
    "    \"\"\"\n",
    "    file_list = glob.glob(os.path.join(folder_name, file_pattern))\n",
    "    articles = {}\n",
    "    article_id_list, sentence_id_list, sentence_list = ([], [], [])\n",
    "    for filename in sorted(file_list):\n",
    "        article_id = os.path.basename(filename).split(\".\")[0][7:]\n",
    "        with codecs.open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "            articles[article_id] = f.read()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqC8_wk6M2d7"
   },
   "outputs": [],
   "source": [
    "dev_folder = \"/content/drive/MyDrive/NLP/project_5_data/datasets/dev-articles\" # check that the path to the datasets folder is correct, if not adjust these variables accordingly \n",
    "propaganda_techniques_file = \"/content/drive/MyDrive/NLP/project_5_data/propaganda-techniques-scorer/data/propaganda-techniques-names-semeval2020task11.txt\" # propaganda_techniques_file is in the tools.tgz file (download it from the team page)\n",
    "task_SI_output_file = \"/content/drive/MyDrive/NLP/project_5_data/bert_base_SI_output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YU4Zg6aieW_O"
   },
   "outputs": [],
   "source": [
    "# !python3 task-SI_scorer.py -s project_5_data/baseline-output-SI.txt -r project_5_data/datasets/dev-labels-task-si/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bg0jS7l3eZLB"
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(train_folder, \"*.txt\"))\n",
    "train_articles_content, train_articles_id = ([], [])\n",
    "for filename in file_list:\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        train_articles_content.append(' '.join([line.strip() for line in f]))\n",
    "        train_articles_id.append(os.path.basename(filename).split(\".\")[0][7:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t82UPVQizKnx",
    "outputId": "914232f6-bb7e-4cf2-8513-b3bfe148e7d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371, 75)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_articles = read_articles_from_file_list(train_folder)\n",
    "dev_articles = read_articles_from_file_list(dev_folder)\n",
    "\n",
    "len(train_articles), len(dev_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCD14ScF0DRa"
   },
   "outputs": [],
   "source": [
    "TASK_3_ARTICLE_ID_COL = 0\n",
    "#TASK_3_TECHNIQUE_NAME_COL = 1\n",
    "TASK_3_FRAGMENT_START_COL = 1\n",
    "TASK_3_FRAGMENT_END_COL = 2\n",
    "\n",
    "def extract_article_id_from_file_name(fullpathfilename):\n",
    "\n",
    "    regex = re.compile(\"article([0-9]+).*\")\n",
    "    return regex.match(os.path.basename(fullpathfilename)).group(1)\n",
    "\n",
    "   \n",
    "def load_annotation_list_from_folder(folder_name, techniques_names):\n",
    "\n",
    "    file_list = glob.glob(os.path.join(folder_name, \"*.labels\"))\n",
    "    if len(file_list)==0:\n",
    "        print(\"Cannot load file list in folder \" + folder_name)\n",
    "        sys.exit()\n",
    "    annotations = {}\n",
    "    for filename in file_list:\n",
    "        annotations[extract_article_id_from_file_name(filename)] = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            for row_number, line in enumerate(f.readlines()):\n",
    "                row = line.rstrip().split(\"\\t\")\n",
    "                annotations[row[TASK_3_ARTICLE_ID_COL]].append((row[TASK_3_FRAGMENT_START_COL], row[TASK_3_FRAGMENT_END_COL]))\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oj4NcyRg2TMR"
   },
   "outputs": [],
   "source": [
    "techniques_names = [ \"propaganda\" ]\n",
    "train_annotation = load_annotation_list_from_folder(train_labels_file, techniques_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTc14E5gHXOG"
   },
   "outputs": [],
   "source": [
    "train_labels = {}\n",
    "for article in train_articles.keys():\n",
    "    labels = [0] * len(train_articles[article])\n",
    "    for annot in train_annotation[article]:\n",
    "        labels[int(annot[0]):int(annot[1])+1] = [1] * (int(annot[1]) - int(annot[0]) + 1)\n",
    "    train_labels[article] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDUqX-_iwf3B"
   },
   "outputs": [],
   "source": [
    "train_labels_str = {}\n",
    "for article_id in train_articles.keys():\n",
    "    index = 0\n",
    "    word_index = 0\n",
    "    # labels = [0] * len(train_articles[article_id].replace('\\n\\n',' ').split(' '))\n",
    "    labels = [0] * len(train_articles[article_id].replace('\\n\\n',' ').replace('\\n', ' ').strip().split(' '))\n",
    "    labels_str = ['O'] * len(labels)\n",
    "\n",
    "    for sentence in train_articles[article_id].replace('\\n', ' ').strip().split('  '):\n",
    "        for word in sentence.split(' '):\n",
    "            if train_labels[article_id][index] == 1:\n",
    "                labels[word_index] = 1\n",
    "                labels_str[word_index] = 'I-Prop'\n",
    "            word_index += 1\n",
    "            index += len(word) + 1\n",
    "        index += 1\n",
    "\n",
    "    train_labels[article_id] = labels\n",
    "    train_labels_str[article_id] = labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8KGnC4UIvVj",
    "outputId": "fd09d6b8-e9ad-4153-fdf5-06f99b24425e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371, 371)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels), len(train_labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnYSkHnFKKAk"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns = ['ID','text','labels'])\n",
    "count = 0\n",
    "for article_id in train_articles.keys():\n",
    "    train_df.loc[count,'ID'] = article_id\n",
    "    train_df.loc[count,'text'] = train_articles[article_id].replace('\\n\\n',' ').replace('\\n', ' ').strip()\n",
    "    temp_label = [str(i) for i in train_labels_str[article_id]]\n",
    "    train_df.loc[count,'labels'] = ','.join(temp_label)\n",
    "    count+=1\n",
    "# del train_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "xuZtyEikLKSg",
    "outputId": "928f6160-0fe7-473a-9f06-1313565c58ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5b1d756d-4f2e-48a1-9da7-30b02fcd008a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>Next plague outbreak in Madagascar could be 's...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111112</td>\n",
       "      <td>US bloggers banned from entering UK Two promin...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111113</td>\n",
       "      <td>Kate Steinle's death at the hands of a Mexican...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111114</td>\n",
       "      <td>U.S. judge frees Indonesian immigrant held by ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111115</td>\n",
       "      <td>Here are all the sexual misconduct accusations...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>999001296</td>\n",
       "      <td>Altered Election Documents Tied To Florida Dem...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>999001297</td>\n",
       "      <td>Migrant Caravan Reach Border &amp; Climb Atop Fenc...</td>\n",
       "      <td>O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>999001619</td>\n",
       "      <td>Guardian ups its vilification of Julian Assang...</td>\n",
       "      <td>O,O,O,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>999001621</td>\n",
       "      <td>This Guardian Fake News Story Proves That The ...</td>\n",
       "      <td>I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>999001970</td>\n",
       "      <td>SNL Indian Comedian Silenced for \"Offensive Jo...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b1d756d-4f2e-48a1-9da7-30b02fcd008a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5b1d756d-4f2e-48a1-9da7-30b02fcd008a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5b1d756d-4f2e-48a1-9da7-30b02fcd008a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            ID                                               text  \\\n",
       "0    111111111  Next plague outbreak in Madagascar could be 's...   \n",
       "1    111111112  US bloggers banned from entering UK Two promin...   \n",
       "2    111111113  Kate Steinle's death at the hands of a Mexican...   \n",
       "3    111111114  U.S. judge frees Indonesian immigrant held by ...   \n",
       "4    111111115  Here are all the sexual misconduct accusations...   \n",
       "..         ...                                                ...   \n",
       "366  999001296  Altered Election Documents Tied To Florida Dem...   \n",
       "367  999001297  Migrant Caravan Reach Border & Climb Atop Fenc...   \n",
       "368  999001619  Guardian ups its vilification of Julian Assang...   \n",
       "369  999001621  This Guardian Fake News Story Proves That The ...   \n",
       "370  999001970  SNL Indian Comedian Silenced for \"Offensive Jo...   \n",
       "\n",
       "                                                labels  \n",
       "0    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "2    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "4    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "..                                                 ...  \n",
       "366  O,O,O,O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-P...  \n",
       "367  O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,...  \n",
       "368  O,O,O,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
       "369  I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Prop,I-Pr...  \n",
       "370  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "\n",
       "[371 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-JMIkhLflie"
   },
   "outputs": [],
   "source": [
    "new_train_df = pd.DataFrame(columns = train_df.columns)\n",
    "count = 0\n",
    "no_words = 256\n",
    "for i in range(len(train_df)):\n",
    "  start = 0\n",
    "  while(True):\n",
    "    text1 = ' '.join(train_df.loc[i,'text'].split(' ')[start:start+no_words])\n",
    "    new_train_df.loc[count,'ID'] = train_df.loc[i,'ID']\n",
    "    new_train_df.loc[count,'text'] = text1\n",
    "    new_train_df.loc[count,'labels'] = ','.join(train_df.loc[i,'labels'].split(',')[start:start+no_words])\n",
    "    count+=1\n",
    "    start+=no_words\n",
    "    if(start>=len(train_df.loc[i,'text'].split(' '))):\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "AQ6wH7eYVYnI",
    "outputId": "4d716923-ca2b-4fe6-fd74-b06f60049ebe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d312ef08-2845-4694-a6e3-4eebcc9e3126\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>Next plague outbreak in Madagascar could be 's...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111111</td>\n",
       "      <td>not over. The larger-than-usual outbreak had h...</td>\n",
       "      <td>I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111112</td>\n",
       "      <td>US bloggers banned from entering UK Two promin...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111112</td>\n",
       "      <td>speakers who promote hate.\" EDL leader Tommy R...</td>\n",
       "      <td>I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111112</td>\n",
       "      <td>home secretary believes they would \"continue t...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>999001621</td>\n",
       "      <td>it. Jonathan Cook, a former Guardian writer, m...</td>\n",
       "      <td>I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>999001621</td>\n",
       "      <td>the journalists? ... Harding is likely a major...</td>\n",
       "      <td>I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>999001621</td>\n",
       "      <td>| Permalink Comments</td>\n",
       "      <td>O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>999001970</td>\n",
       "      <td>SNL Indian Comedian Silenced for \"Offensive Jo...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>999001970</td>\n",
       "      <td>him with a few moments for closing remarks. Co...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,I-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d312ef08-2845-4694-a6e3-4eebcc9e3126')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d312ef08-2845-4694-a6e3-4eebcc9e3126 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d312ef08-2845-4694-a6e3-4eebcc9e3126');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             ID                                               text  \\\n",
       "0     111111111  Next plague outbreak in Madagascar could be 's...   \n",
       "1     111111111  not over. The larger-than-usual outbreak had h...   \n",
       "2     111111112  US bloggers banned from entering UK Two promin...   \n",
       "3     111111112  speakers who promote hate.\" EDL leader Tommy R...   \n",
       "4     111111112  home secretary believes they would \"continue t...   \n",
       "...         ...                                                ...   \n",
       "1522  999001621  it. Jonathan Cook, a former Guardian writer, m...   \n",
       "1523  999001621  the journalists? ... Harding is likely a major...   \n",
       "1524  999001621                               | Permalink Comments   \n",
       "1525  999001970  SNL Indian Comedian Silenced for \"Offensive Jo...   \n",
       "1526  999001970  him with a few moments for closing remarks. Co...   \n",
       "\n",
       "                                                 labels  \n",
       "0     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1     I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "2     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3     I-Prop,I-Prop,I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,...  \n",
       "4                                   O,O,O,O,O,O,O,O,O,O  \n",
       "...                                                 ...  \n",
       "1522  I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
       "1523  I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1524                                              O,O,O  \n",
       "1525  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1526  O,O,O,O,O,O,O,O,I-Prop,I-Prop,I-Prop,I-Prop,I-...  \n",
       "\n",
       "[1527 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQjRdlQlgMCt",
    "outputId": "86fb606a-d6f7-4dc3-e43a-fe95276cd6ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_df.loc[2,'text'].split(' ')), len(new_train_df.loc[2,'labels'].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvfXNncxgNRL"
   },
   "outputs": [],
   "source": [
    "train_df = new_train_df\n",
    "del train_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJ4ePHvFPP9c",
    "outputId": "caa99fd1-42e1-4026-bbd3-b3c5f6f70338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'I-Prop': 0, 'O': 1}, {0: 'I-Prop', 1: 'O'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels_to_ids = {k: v for v, k in enumerate(['B-Prop','I-Prop', 'O'])}\n",
    "# ids_to_labels = {v: k for v, k in enumerate(['B-Prop','I-Prop', 'O'])}\n",
    "# labels_to_ids, ids_to_labels\n",
    "\n",
    "labels_to_ids = {k: v for v, k in enumerate(['I-Prop', 'O'])}\n",
    "ids_to_labels = {v: k for v, k in enumerate(['I-Prop', 'O'])}\n",
    "labels_to_ids, ids_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xZtk9jGLVoI"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 1\n",
    "DEV_BATCH_SIZE = 1\n",
    "EPOCHS = 7\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0f088e6567084637a9d4bf339978175c",
      "8aa2bb2722714a438527772ebeddf1da",
      "fcf0a233fcde4314b10e1a5076422b6a",
      "8629b2eb57084fd2a2a7241daafa614f",
      "088b20a3ec274b85b036a5d57cbce488",
      "cd5f97572eac468fbb71ed586c3ce6f9",
      "3799f9991c6f47dfbeef4aa9006f568b",
      "7cf03e6380ab4029a2fed2e32c4e62e3",
      "56cc4a25122c480098a7df15cdefc3d5",
      "3d64e49760e740bf869460d7a55cf502",
      "4fd958732ad644a891a017330465644d"
     ]
    },
    "id": "Usg6tiN-U-Sc",
    "outputId": "0b66709f-5db4-4edc-a653-d494bdaa628b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f088e6567084637a9d4bf339978175c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cn_W5QbwMaMq"
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.text[index].strip().split(' ')  \n",
    "        word_labels = self.data.labels[index].split(\",\") \n",
    "\n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             is_pretokenized=True, \n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "\n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "\n",
    "        # # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "          if mapping[0] == 0 and mapping[1] != 0:\n",
    "            # overwrite label\n",
    "            encoded_labels[idx] = labels[i]\n",
    "            i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EifAo7mAMogL",
    "outputId": "6dad0fa8-77d1-4fb9-dec2-da22fdedad5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (1527, 2)\n",
      "TRAIN Dataset: (1527, 2)\n",
      "TEST Dataset: (0, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 1\n",
    "train_dataset = train_df.sample(frac=train_size,random_state=200)\n",
    "test_dataset = train_df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(train_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdbvIAqoME-l",
    "outputId": "23eb2517-0e89-46ab-d2ea-468eef38265c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'input_ids': tensor([  101,   789,   786,  2926,   117,  2639,   117,  1321,  1103, 16025,\n",
       "          1148,   117,  1105,  1173,  1301,  1106,  2175,   117,   787,  8499,\n",
       "          5133,   119,   790,  3969,  1103,  5551,  1303,   131,  2631,  1323,\n",
       "         20507,  5096,  5710,  3284,  2372, 12554,  2008,  1130,  5096, 19000,\n",
       "          1916, 11155,  2119,   117,  8499,   787,   188,  8477,  1132,  1208,\n",
       "          1103, 11158,  1158,  5354,  1111,  2560,  6387, 11697,  1155,  1166,\n",
       "          1738,  1106,  4035, 11179,  2560, 14255,  8702, 26996,  2116,  3892,\n",
       "           119,  1573,  1677,   117,  1421,  2231,  1138,  2085,   789,  1894,\n",
       "          5167,   790,  3892,  1115,  2621,  2021,  6421,  1106, 14255,  8702,\n",
       "         26996,  1566,  3832,  1121,  1800,  8012,  1106,  1129,   789,  4249,\n",
       "           790,  1118,  1719,   170,  1644,  7742,  2575,  1137,   170,  1266,\n",
       "          1420,   139, 14663,  9565,  2036,  1103,  2510,  1144,  4762,  1251,\n",
       "          3755,   117,  1105,  1107,  1141,  1426,   113,  9502,  2054,   114,\n",
       "          1103,  4066,  3010,  1126,  3275,  1546, 16381,   170,   789,  1894,\n",
       "          5167,   790,  1644,   119,  3446,  1132,  1103,  1565,  2231,  1187,\n",
       "          1103,  8312,  1116,  1138,  1640,  2085,   783,  1137,  1103,  4066,\n",
       "          1144,  1640,  3010,  1126,  3275,  1546, 16381,   783,   789,  1894,\n",
       "          5167,   790,  3892,   131,  1756,  5432,  4456,  4660,  1994,  9502,\n",
       "          2054,  1262,  1290,  8499,   787,   188, 13406,  1776,  8477,   117,\n",
       "          1175,  1132,  1120,  1655,  1572,  2509,  2231,  1115,  1132,  1971,\n",
       "          6103,  3744,   789,  1894,  5167,   790,  3892,   119,  1636,  1132,\n",
       "           131,  5359,  6883,  4565,  8056,  2631,  6826,  3461,  5258,  4312,\n",
       "          4875,  4624,  3559,  3312,  4332,  4499,  1203,  3308,  1203,  1365,\n",
       "          1456,  2938,  3197,  2680,  4513,  6041,  8472,  2550,  1262,  1122,\n",
       "           787,   188,  1136,  1781,  1263,  1111,  1644,  7742,  6421,  1107,\n",
       "          1103,  1807,  2231,  1106,  3295,  1147,  5755,  1279,  3530,  5937,\n",
       "          1113,  2560,  5032,   119,  1188,  2592,  1110,  1121,  5160,   131,\n",
       "          2091, 10354, 14629,  1116,   117,  1242,  1168,  2231,  1132,  1145,\n",
       "          6103,  3744,   789,  1894,  5167,   790,  3892,   119,   789,  1109,\n",
       "          1331,   787,   188,  2021,  2853,  1245,  1103,  1148,  1644,  7742,\n",
       "          4792,  1107,  1103,  1352,  1106,  2049,  1103,  7906,  1104,   170,\n",
       "         27356,  1223,   170,  1207,  1644,  1227,  1112,  1126,   786,  6122,\n",
       "          3187,  3636,  1546,   119,   787,   789,  1109,  4497,  6808,   170,\n",
       "          1299,  1150,  2491,  1107,  4720,  3305,   117,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'labels': tensor([-100,    1, -100, -100, -100,    1, -100,    1,    1,    1,    1, -100,\n",
       "            1,    1,    1,    1,    1, -100, -100,    1,    1, -100, -100,    1,\n",
       "            1,    1,    1, -100,    1,    1,    1,    1, -100,    1,    1,    1,\n",
       "         -100,    1,    1, -100, -100,    1,    1, -100,    1, -100, -100,    1,\n",
       "            1,    1,    1,    0, -100,    0,    1,    1,    1, -100,    1,    1,\n",
       "            1,    1,    1, -100,    1,    1, -100, -100, -100,    1, -100,    1,\n",
       "            1, -100,    1,    1,    1,    1,    1, -100,    1, -100,    1,    1,\n",
       "            1,    1,    1,    1,    1, -100, -100, -100,    1,    1,    1,    1,\n",
       "            1,    1,    1, -100, -100,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1, -100, -100, -100,    1,    1,    1,    1,    1,\n",
       "            1, -100,    1,    1,    1,    1,    1, -100,    1, -100,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1, -100,    1, -100,    1, -100,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1, -100,    1,    1,    1,\n",
       "         -100, -100,    1,    1,    1,    1,    1,    1,    1,    1,    1, -100,\n",
       "         -100, -100,    1, -100,    1, -100,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1, -100, -100,    0, -100,    0, -100,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1, -100,\n",
       "            1, -100,    1, -100,    1,    1, -100,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "         -100, -100,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1, -100, -100,    1,    1,    1,    1, -100,\n",
       "            1,    1,    1,    1,    1, -100, -100, -100, -100, -100, -100,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1, -100,    1, -100,    1, -100,\n",
       "            1, -100,    1, -100, -100,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1, -100,    1,    1,    1, -100,\n",
       "         -100,    1, -100,    1,    1,    1,    1,    1,    1,    1,    1, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]),\n",
       " 'offset_mapping': tensor([[0, 0],\n",
       "         [0, 1],\n",
       "         [1, 2],\n",
       "         ...,\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[1209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04_uth-tOC1x",
    "outputId": "417e85e4-8ad5-45eb-cff4-0e22f3d9a4a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] “ ‘ Or, Mike, take the firearms first, and then go to court, ’ Trump responded. ” See the column here : Florida School Massacre Proves Police Are Worthless In Protecting Us Well, Trump ’ s statements are now the rallying cry for gun grabbers all over America to enact gun confiscation laws. So far, five states have passed “ red flag ” laws that allow police agencies to confiscate guns from someone deemed to be “ dangerous ” by either a law enforcement officer or a family member BEFORE the individual has committed any crime, and in one State ( Rhode Island ) the governor issued an executive order implementing a “ red flag ” law. Here are the six states where the legislatures have already passed — or the governor has already issued an executive order implementing — “ red flag ” laws : California Connecticut Indiana Oregon Washington Rhode Island And since Trump ’ s Stalinist statements, there are at least 24 additional states that are currently considering passing “ red flag ” laws. These are : Alabama Alaska Arizona Delaware Florida Hawaii Illinois Iowa Kansas Kentucky Maryland Massachusetts Michigan Minnesota Missouri New Jersey New York North Carolina Ohio Pennsylvania Tennessee Utah Vermont Virginia And it ’ s not taking long for law enforcement agencies in the above states to begin their Naziesque assault on gun owners. This report is from Seattle : Doubtless, many other states are also considering passing “ red flag ” laws. “ The city ’ s police department became the first law enforcement agency in the state to force the surrender of a firearm under a new law known as an ‘ extreme risk protection order. ’ “ The incident involves a man who lives in Belltown, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(training_set[1209][\"input_ids\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtLQ091b4Gpw"
   },
   "outputs": [],
   "source": [
    "for token, mapping, label in zip(tokenizer.convert_ids_to_tokens(training_set[1209][\"input_ids\"]), training_set[1209]['offset_mapping'], training_set[1209][\"labels\"]):\n",
    "    print('{0:10} {1:4}  {2:15}'.format(token, label.item(), str(mapping.tolist())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt-Hx7yvM4K0"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "# testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f1cdaa5e89694501bcfa8a72922f602d",
      "eefc9bb93bc741aa8d8a0096d2e0ccb8",
      "41ae8d01a95c4c0b809e1f2fa4a0d969",
      "51b43206e99c41489b6581846a267025",
      "90bd1a934ba547aab2a88d78b546434d",
      "5760ab3c75dd4e80b7232703a00c0d07",
      "f035dc4f96d242ab817d3d7926bcb27f",
      "9a27b2173bc24358a41e5b8a17ae2503",
      "9ac991660dff47c98458e707fbd5dafe",
      "32e0a78b254745a783fc3412886e324c",
      "82629a9d13cc4051928e8399ab374c83",
      "6fe36b3e72624b10957e06f8516d7d1a",
      "33677c96c34c4cdf94c352cc2a8ab365",
      "88c1920c84e64737b0d158697c30fd9c",
      "534dc8078add4bd895a22fc52bc25c18",
      "62cbd534684c47a9b8395fabd4a3fbdd",
      "a07db69e1b3b4ad7b998544de1aa1f8c",
      "86ef9b2a73f146b8aeb9a0150d3d785d",
      "be101f8a16e8403298554172effc6b24",
      "91bdbc75bd094cc38eaec64779318e06",
      "0e1cd53f0ee5408489ee8cc97bd78ff0",
      "49a9c2438aeb4c8caaadc37cd1099f87"
     ]
    },
    "id": "KKmKQIn9M89Q",
    "outputId": "9514635e-4300-46db-c489-27e28cc8e320"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cdaa5e89694501bcfa8a72922f602d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe36b3e72624b10957e06f8516d7d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5P2SDc5M-cl",
    "outputId": "ba2ce6b6-4b9a-46a1-ff24-9887b18a8b6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6762, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       " (tensor(0.6762, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       "  tensor([[[-0.1447, -0.1800],\n",
       "           [ 0.0464, -0.0893],\n",
       "           [-0.1756,  0.0261],\n",
       "           ...,\n",
       "           [-0.1696, -0.0362],\n",
       "           [-0.2404, -0.0022],\n",
       "           [-0.2694,  0.0035]]], device='cuda:0', grad_fn=<AddBackward0>)))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmsTVYguXyXC",
    "outputId": "5575f7a3-9a70-465e-bffe-d692526f02db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XccWGsGWWSrc",
    "outputId": "4fa361a0-e1c7-4857-afe6-b22974ee2bd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUhxv8JbS4ag",
    "outputId": "bebf5ce5-b2e0-42b2-d896-54f750824114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQ7VzuqrVMuw"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3urEiVB8VU-t"
   },
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOtLvgsvChES"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqAS88OlVWG2",
    "outputId": "1ff22ce8-c7d1-4fac-f135-426365208d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 0.6731213331222534\n",
      "Training loss per 100 training steps: 0.36469194492196094\n",
      "Training loss per 100 training steps: 0.36604528881572373\n",
      "Training loss per 100 training steps: 0.35950693683667834\n",
      "Training loss per 100 training steps: 0.35241291623683346\n",
      "Training loss per 100 training steps: 0.3470288377158537\n",
      "Training loss per 100 training steps: 0.34486925150089576\n",
      "Training loss per 100 training steps: 0.3387239161246428\n",
      "Training loss epoch: 0.33997073834420655\n",
      "Training accuracy epoch: 0.8688673192917337\n",
      "Training epoch: 2\n",
      "Training loss per 100 training steps: 0.35091111063957214\n",
      "Training loss per 100 training steps: 0.26659484679746154\n",
      "Training loss per 100 training steps: 0.27978445767466703\n",
      "Training loss per 100 training steps: 0.29411227562065634\n",
      "Training loss per 100 training steps: 0.2948704770048546\n",
      "Training loss per 100 training steps: 0.29211264815434307\n",
      "Training loss per 100 training steps: 0.2895309706815145\n",
      "Training loss per 100 training steps: 0.28617823408642906\n",
      "Training loss epoch: 0.2842490087392501\n",
      "Training accuracy epoch: 0.8817089427996923\n",
      "Training epoch: 3\n",
      "Training loss per 100 training steps: 0.24774831533432007\n",
      "Training loss per 100 training steps: 0.2310517064138952\n",
      "Training loss per 100 training steps: 0.21956024360171153\n",
      "Training loss per 100 training steps: 0.21868420021292875\n",
      "Training loss per 100 training steps: 0.21431632076582854\n",
      "Training loss per 100 training steps: 0.2138692552926476\n",
      "Training loss per 100 training steps: 0.21655347428521676\n",
      "Training loss per 100 training steps: 0.21413461717321258\n",
      "Training loss epoch: 0.21471357033880553\n",
      "Training accuracy epoch: 0.9098761551096495\n",
      "Training epoch: 4\n",
      "Training loss per 100 training steps: 0.4387665390968323\n",
      "Training loss per 100 training steps: 0.14996888217433255\n",
      "Training loss per 100 training steps: 0.15158787604180438\n",
      "Training loss per 100 training steps: 0.15219771974964494\n",
      "Training loss per 100 training steps: 0.15163211288985023\n",
      "Training loss per 100 training steps: 0.14985880408688873\n",
      "Training loss per 100 training steps: 0.15140486779326756\n",
      "Training loss per 100 training steps: 0.1495461889300841\n",
      "Training loss epoch: 0.14818683038014646\n",
      "Training accuracy epoch: 0.9402789007105951\n",
      "Training epoch: 5\n",
      "Training loss per 100 training steps: 0.11629360914230347\n",
      "Training loss per 100 training steps: 0.10637938860564096\n",
      "Training loss per 100 training steps: 0.10240822353062048\n",
      "Training loss per 100 training steps: 0.10503105056221501\n",
      "Training loss per 100 training steps: 0.10556525996158381\n",
      "Training loss per 100 training steps: 0.10523713425392268\n",
      "Training loss per 100 training steps: 0.10793693186801442\n",
      "Training loss per 100 training steps: 0.10704280185559199\n",
      "Training loss epoch: 0.10693955604729508\n",
      "Training accuracy epoch: 0.9588332982056094\n",
      "Training epoch: 6\n",
      "Training loss per 100 training steps: 0.08224697411060333\n",
      "Training loss per 100 training steps: 0.0811378508737071\n",
      "Training loss per 100 training steps: 0.0762795179309694\n",
      "Training loss per 100 training steps: 0.07697296526439278\n",
      "Training loss per 100 training steps: 0.08059507669176108\n",
      "Training loss per 100 training steps: 0.08160347177553179\n",
      "Training loss per 100 training steps: 0.08079105640274198\n",
      "Training loss per 100 training steps: 0.0816708489908397\n",
      "Training loss epoch: 0.08065900169645134\n",
      "Training accuracy epoch: 0.9692789001649303\n",
      "Training epoch: 7\n",
      "Training loss per 100 training steps: 0.06728766858577728\n",
      "Training loss per 100 training steps: 0.06870575092610728\n",
      "Training loss per 100 training steps: 0.06551421819682192\n",
      "Training loss per 100 training steps: 0.06380170106557523\n",
      "Training loss per 100 training steps: 0.06734183992092566\n",
      "Training loss per 100 training steps: 0.06562524764208837\n",
      "Training loss per 100 training steps: 0.06482923981710763\n",
      "Training loss per 100 training steps: 0.06536589004240528\n",
      "Training loss epoch: 0.06504371118570583\n",
      "Training accuracy epoch: 0.976212483709232\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(7):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypSTu9bAHUzy"
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"/content/drive/MyDrive/NLP/BERT_Task_SI.pt\")\n",
    "# model = torch.load(\"/content/drive/MyDrive/NLP/BERT_Task_SI.pt\", map_location=torch.device('cpu'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVEy7H9xVYPS"
   },
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            # temp_labels = labels\n",
    "            # print(idx,labels)\n",
    "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            # print(temp_labels == labels)\n",
    "\n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            # eval_labels.extend(flattened_targets)\n",
    "            # eval_preds.extend(flattened_predictions)\n",
    "            \n",
    "            # tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpWv5P1ZtruV"
   },
   "outputs": [],
   "source": [
    "# labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQzeCsx7tEWi"
   },
   "outputs": [],
   "source": [
    "dev_annotation = load_annotation_list_from_folder(dev_labels_file, techniques_names)\n",
    "\n",
    "dev_labels = {}\n",
    "for article in dev_articles.keys():\n",
    "    labels = [0] * len(dev_articles[article])\n",
    "    for annot in dev_annotation[article]:\n",
    "        labels[int(annot[0]):int(annot[1])] = [1] * (int(annot[1]) - int(annot[0]))\n",
    "    dev_labels[article] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynfq9JDVPje-"
   },
   "outputs": [],
   "source": [
    "dev_labels_str = {}\n",
    "for article_id in dev_articles.keys():\n",
    "    index = 0\n",
    "    word_index = 0\n",
    "\n",
    "    labels = [0] * len(dev_articles[article_id].replace('\\n\\n','\\n').replace('\\n', ' ').strip().split(' '))\n",
    "    labels_str = ['O'] * len(labels)\n",
    "    \n",
    "    first_sentence = True\n",
    "    for sentence in dev_articles[article_id].replace('\\n\\n', '\\n').strip().split('\\n'):\n",
    "        for word in sentence.split(' '):\n",
    "            if dev_labels[article_id][index] == 1:\n",
    "                labels[word_index] = 1\n",
    "                labels_str[word_index] = 'I-Prop'\n",
    "            word_index += 1\n",
    "            index += len(word) + 1\n",
    "        if first_sentence:\n",
    "            first_sentence = False\n",
    "            index += 1\n",
    "        # index += 1\n",
    "\n",
    "    dev_labels[article_id] = labels\n",
    "    dev_labels_str[article_id] = labels_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cl8N4U3lQEl6"
   },
   "outputs": [],
   "source": [
    "dev_df = pd.DataFrame(columns = ['ID','text','labels'])\n",
    "count = 0\n",
    "for article_id in dev_articles.keys():\n",
    "    dev_df.loc[count,'ID'] = article_id\n",
    "    dev_df.loc[count,'text'] = dev_articles[article_id].replace('\\n\\n','\\n').replace('\\n', ' ').strip()\n",
    "    temp_label = [label for label in dev_labels_str[article_id]]\n",
    "    dev_df.loc[count,'labels'] = ','.join(temp_label)\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Cje7WJSBoST"
   },
   "outputs": [],
   "source": [
    "new_dev_df = pd.DataFrame(columns = dev_df.columns)\n",
    "count = 0\n",
    "no_words = 256\n",
    "for i in range(len(dev_df)):\n",
    "    start = 0\n",
    "    while(True):\n",
    "        text1 = ' '.join(dev_df.loc[i,'text'].split(' ')[start:start+no_words])\n",
    "        new_dev_df.loc[count,'ID'] = dev_df.loc[i,'ID']\n",
    "        new_dev_df.loc[count,'text'] = text1\n",
    "        new_dev_df.loc[count,'labels'] = ','.join(dev_df.loc[i,'labels'].split(',')[start:start+no_words])\n",
    "        count+=1\n",
    "        start+=no_words\n",
    "        if(start>=len(dev_df.loc[i,'text'].split(' '))):\n",
    "            break\n",
    "\n",
    "dev_df = new_dev_df\n",
    "dev_id = dev_df['ID']\n",
    "del dev_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "clUUNNSEImZ2",
    "outputId": "3e8ce40c-17f4-4562-e9a4-a37d95055657"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c59001a6-27e8-4c8a-8b32-0be480702ef1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police had previously gone to home where Ohio ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>could be heard yelling, ‘‘We have shots fired....</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>America's Immigration Voice. Earlier, I blogge...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,I-Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>since 2017, some for alleged domestic violence...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man arrested for allegedly buying gun used in ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Press and the Los Angeles Times are among the ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Trump Vows to Kick CNN’s Acosta Out Again Pres...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>news conference,\" Trump said. Acosta’s hard pa...</td>\n",
       "      <td>I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>forward to continuing to defend the White Hous...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,I-Prop,O,O,I-Prop,I-Prop,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>is continuing to violate the First and 5th Ame...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c59001a6-27e8-4c8a-8b32-0be480702ef1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c59001a6-27e8-4c8a-8b32-0be480702ef1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c59001a6-27e8-4c8a-8b32-0be480702ef1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Police had previously gone to home where Ohio ...   \n",
       "1    could be heard yelling, ‘‘We have shots fired....   \n",
       "2    America's Immigration Voice. Earlier, I blogge...   \n",
       "3    since 2017, some for alleged domestic violence...   \n",
       "4    Man arrested for allegedly buying gun used in ...   \n",
       "..                                                 ...   \n",
       "257  Press and the Los Angeles Times are among the ...   \n",
       "258  Trump Vows to Kick CNN’s Acosta Out Again Pres...   \n",
       "259  news conference,\" Trump said. Acosta’s hard pa...   \n",
       "260  forward to continuing to defend the White Hous...   \n",
       "261  is continuing to violate the First and 5th Ame...   \n",
       "\n",
       "                                                labels  \n",
       "0    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "2    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,I-Pr...  \n",
       "3    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "4    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "..                                                 ...  \n",
       "257  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "258  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "259  I-Prop,I-Prop,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "260  O,O,O,O,O,O,O,O,I-Prop,O,O,I-Prop,I-Prop,O,O,O...  \n",
       "261  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "\n",
       "[262 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBU-DskwfoyD"
   },
   "outputs": [],
   "source": [
    "#All data in dev set\n",
    "dev_dataset = dev_df\n",
    "\n",
    "dev_set = dataset(dev_dataset, tokenizer, MAX_LEN)\n",
    "dev_params = {'batch_size': DEV_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "\n",
    "dev_loader = DataLoader(dev_set, **dev_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t103YXfRREiO",
    "outputId": "e09cc04e-4851-40b4-be80-37e96f943e37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      730081389\n",
       "1      730081389\n",
       "2      730093263\n",
       "3      730093263\n",
       "4      730246508\n",
       "         ...    \n",
       "257    999001323\n",
       "258    999001419\n",
       "259    999001419\n",
       "260    999001419\n",
       "261    999001419\n",
       "Name: ID, Length: 262, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPT_hwe_y9XH",
    "outputId": "1dd6cbf6-6162-4b5d-ae42-9a538c3cb326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.0010113143362104893\n",
      "Validation Loss: 0.0010113143362104893\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.003582330420613289\n",
      "Validation Loss: 0.003582330420613289\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.057770878076553345\n",
      "Validation Loss: 0.057770878076553345\n",
      "Validation Accuracy: 0.98828125\n",
      "Validation loss per 100 evaluation steps: 0.6879169344902039\n",
      "Validation Loss: 0.6879169344902039\n",
      "Validation Accuracy: 0.8256880733944955\n",
      "Validation loss per 100 evaluation steps: 0.0011655106209218502\n",
      "Validation Loss: 0.0011655106209218502\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.02388973906636238\n",
      "Validation Loss: 0.02388973906636238\n",
      "Validation Accuracy: 0.99609375\n",
      "Validation loss per 100 evaluation steps: 0.30000999569892883\n",
      "Validation Loss: 0.30000999569892883\n",
      "Validation Accuracy: 0.89453125\n",
      "Validation loss per 100 evaluation steps: 0.6449406147003174\n",
      "Validation Loss: 0.6449406147003174\n",
      "Validation Accuracy: 0.7443609022556391\n",
      "Validation loss per 100 evaluation steps: 0.09894227981567383\n",
      "Validation Loss: 0.09894227981567383\n",
      "Validation Accuracy: 0.9716312056737588\n",
      "Validation loss per 100 evaluation steps: 0.32987356185913086\n",
      "Validation Loss: 0.32987356185913086\n",
      "Validation Accuracy: 0.8671875\n",
      "Validation loss per 100 evaluation steps: 0.6419988870620728\n",
      "Validation Loss: 0.6419988870620728\n",
      "Validation Accuracy: 0.75\n",
      "Validation loss per 100 evaluation steps: 1.8107593059539795\n",
      "Validation Loss: 1.8107593059539795\n",
      "Validation Accuracy: 0.6171875\n",
      "Validation loss per 100 evaluation steps: 0.17801311612129211\n",
      "Validation Loss: 0.17801311612129211\n",
      "Validation Accuracy: 0.9296875\n",
      "Validation loss per 100 evaluation steps: 0.36455124616622925\n",
      "Validation Loss: 0.36455124616622925\n",
      "Validation Accuracy: 0.8623188405797102\n",
      "Validation loss per 100 evaluation steps: 0.6026305556297302\n",
      "Validation Loss: 0.6026305556297302\n",
      "Validation Accuracy: 0.84765625\n",
      "Validation loss per 100 evaluation steps: 1.2293018102645874\n",
      "Validation Loss: 1.2293018102645874\n",
      "Validation Accuracy: 0.5862068965517241\n",
      "Validation loss per 100 evaluation steps: 0.6080900430679321\n",
      "Validation Loss: 0.6080900430679321\n",
      "Validation Accuracy: 0.83203125\n",
      "Validation loss per 100 evaluation steps: 0.35520482063293457\n",
      "Validation Loss: 0.35520482063293457\n",
      "Validation Accuracy: 0.9137254901960784\n",
      "Validation loss per 100 evaluation steps: 0.5501441955566406\n",
      "Validation Loss: 0.5501441955566406\n",
      "Validation Accuracy: 0.83984375\n",
      "Validation loss per 100 evaluation steps: 2.11909818649292\n",
      "Validation Loss: 2.11909818649292\n",
      "Validation Accuracy: 0.62109375\n",
      "Validation loss per 100 evaluation steps: 1.3599941730499268\n",
      "Validation Loss: 1.3599941730499268\n",
      "Validation Accuracy: 0.3548387096774194\n",
      "Validation loss per 100 evaluation steps: 0.12532387673854828\n",
      "Validation Loss: 0.12532387673854828\n",
      "Validation Accuracy: 0.953125\n",
      "Validation loss per 100 evaluation steps: 0.0020097095984965563\n",
      "Validation Loss: 0.0020097095984965563\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.029667992144823074\n",
      "Validation Loss: 0.029667992144823074\n",
      "Validation Accuracy: 0.99609375\n",
      "Validation loss per 100 evaluation steps: 0.6710962057113647\n",
      "Validation Loss: 0.6710962057113647\n",
      "Validation Accuracy: 0.8283582089552238\n",
      "Validation loss per 100 evaluation steps: 0.345065176486969\n",
      "Validation Loss: 0.345065176486969\n",
      "Validation Accuracy: 0.88671875\n",
      "Validation loss per 100 evaluation steps: 1.6997064352035522\n",
      "Validation Loss: 1.6997064352035522\n",
      "Validation Accuracy: 0.55078125\n",
      "Validation loss per 100 evaluation steps: 0.025753192603588104\n",
      "Validation Loss: 0.025753192603588104\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.5106001496315002\n",
      "Validation Loss: 0.5106001496315002\n",
      "Validation Accuracy: 0.859375\n",
      "Validation loss per 100 evaluation steps: 0.3341009318828583\n",
      "Validation Loss: 0.3341009318828583\n",
      "Validation Accuracy: 0.8631578947368421\n",
      "Validation loss per 100 evaluation steps: 0.08510912209749222\n",
      "Validation Loss: 0.08510912209749222\n",
      "Validation Accuracy: 0.953125\n",
      "Validation loss per 100 evaluation steps: 0.12816943228244781\n",
      "Validation Loss: 0.12816943228244781\n",
      "Validation Accuracy: 0.9379310344827586\n",
      "Validation loss per 100 evaluation steps: 0.11610901355743408\n",
      "Validation Loss: 0.11610901355743408\n",
      "Validation Accuracy: 0.9453125\n",
      "Validation loss per 100 evaluation steps: 0.48307034373283386\n",
      "Validation Loss: 0.48307034373283386\n",
      "Validation Accuracy: 0.86328125\n",
      "Validation loss per 100 evaluation steps: 0.4180353283882141\n",
      "Validation Loss: 0.4180353283882141\n",
      "Validation Accuracy: 0.8297872340425532\n",
      "Validation loss per 100 evaluation steps: 0.3616122007369995\n",
      "Validation Loss: 0.3616122007369995\n",
      "Validation Accuracy: 0.91015625\n",
      "Validation loss per 100 evaluation steps: 0.21973071992397308\n",
      "Validation Loss: 0.21973071992397308\n",
      "Validation Accuracy: 0.93359375\n",
      "Validation loss per 100 evaluation steps: 0.8052129149436951\n",
      "Validation Loss: 0.8052129149436951\n",
      "Validation Accuracy: 0.8340080971659919\n",
      "Validation loss per 100 evaluation steps: 0.4666275382041931\n",
      "Validation Loss: 0.4666275382041931\n",
      "Validation Accuracy: 0.8515625\n",
      "Validation loss per 100 evaluation steps: 0.14283835887908936\n",
      "Validation Loss: 0.14283835887908936\n",
      "Validation Accuracy: 0.93359375\n",
      "Validation loss per 100 evaluation steps: 0.08334032446146011\n",
      "Validation Loss: 0.08334032446146011\n",
      "Validation Accuracy: 0.96484375\n",
      "Validation loss per 100 evaluation steps: 0.3431742489337921\n",
      "Validation Loss: 0.3431742489337921\n",
      "Validation Accuracy: 0.828125\n",
      "Validation loss per 100 evaluation steps: 1.2026876211166382\n",
      "Validation Loss: 1.2026876211166382\n",
      "Validation Accuracy: 0.6759259259259259\n",
      "Validation loss per 100 evaluation steps: 0.7996777296066284\n",
      "Validation Loss: 0.7996777296066284\n",
      "Validation Accuracy: 0.75\n",
      "Validation loss per 100 evaluation steps: 1.4259240627288818\n",
      "Validation Loss: 1.4259240627288818\n",
      "Validation Accuracy: 0.72265625\n",
      "Validation loss per 100 evaluation steps: 0.771974503993988\n",
      "Validation Loss: 0.771974503993988\n",
      "Validation Accuracy: 0.7109375\n",
      "Validation loss per 100 evaluation steps: 0.3078959584236145\n",
      "Validation Loss: 0.3078959584236145\n",
      "Validation Accuracy: 0.7567567567567568\n",
      "Validation loss per 100 evaluation steps: 0.1872604340314865\n",
      "Validation Loss: 0.1872604340314865\n",
      "Validation Accuracy: 0.9375\n",
      "Validation loss per 100 evaluation steps: 1.0765308141708374\n",
      "Validation Loss: 1.0765308141708374\n",
      "Validation Accuracy: 0.6328125\n",
      "Validation loss per 100 evaluation steps: 1.5095605850219727\n",
      "Validation Loss: 1.5095605850219727\n",
      "Validation Accuracy: 0.50390625\n",
      "Validation loss per 100 evaluation steps: 1.140831470489502\n",
      "Validation Loss: 1.140831470489502\n",
      "Validation Accuracy: 0.62890625\n",
      "Validation loss per 100 evaluation steps: 3.911027193069458\n",
      "Validation Loss: 3.911027193069458\n",
      "Validation Accuracy: 0.2235294117647059\n",
      "Validation loss per 100 evaluation steps: 0.8338984251022339\n",
      "Validation Loss: 0.8338984251022339\n",
      "Validation Accuracy: 0.69921875\n",
      "Validation loss per 100 evaluation steps: 0.8692039251327515\n",
      "Validation Loss: 0.8692039251327515\n",
      "Validation Accuracy: 0.68359375\n",
      "Validation loss per 100 evaluation steps: 0.2549726665019989\n",
      "Validation Loss: 0.2549726665019989\n",
      "Validation Accuracy: 0.90625\n",
      "Validation loss per 100 evaluation steps: 0.8196411728858948\n",
      "Validation Loss: 0.8196411728858948\n",
      "Validation Accuracy: 0.703125\n",
      "Validation loss per 100 evaluation steps: 0.27662843465805054\n",
      "Validation Loss: 0.27662843465805054\n",
      "Validation Accuracy: 0.86328125\n",
      "Validation loss per 100 evaluation steps: 1.2275582551956177\n",
      "Validation Loss: 1.2275582551956177\n",
      "Validation Accuracy: 0.69921875\n",
      "Validation loss per 100 evaluation steps: 1.0306596755981445\n",
      "Validation Loss: 1.0306596755981445\n",
      "Validation Accuracy: 0.66796875\n",
      "Validation loss per 100 evaluation steps: 0.9702261090278625\n",
      "Validation Loss: 0.9702261090278625\n",
      "Validation Accuracy: 0.69921875\n",
      "Validation loss per 100 evaluation steps: 1.5273371934890747\n",
      "Validation Loss: 1.5273371934890747\n",
      "Validation Accuracy: 0.47265625\n",
      "Validation loss per 100 evaluation steps: 0.42623910307884216\n",
      "Validation Loss: 0.42623910307884216\n",
      "Validation Accuracy: 0.7666666666666667\n",
      "Validation loss per 100 evaluation steps: 0.5545456409454346\n",
      "Validation Loss: 0.5545456409454346\n",
      "Validation Accuracy: 0.81640625\n",
      "Validation loss per 100 evaluation steps: 0.6999319195747375\n",
      "Validation Loss: 0.6999319195747375\n",
      "Validation Accuracy: 0.7741935483870968\n",
      "Validation loss per 100 evaluation steps: 0.29263854026794434\n",
      "Validation Loss: 0.29263854026794434\n",
      "Validation Accuracy: 0.8359375\n",
      "Validation loss per 100 evaluation steps: 0.46834397315979004\n",
      "Validation Loss: 0.46834397315979004\n",
      "Validation Accuracy: 0.8046875\n",
      "Validation loss per 100 evaluation steps: 0.5582572817802429\n",
      "Validation Loss: 0.5582572817802429\n",
      "Validation Accuracy: 0.78515625\n",
      "Validation loss per 100 evaluation steps: 0.3107083737850189\n",
      "Validation Loss: 0.3107083737850189\n",
      "Validation Accuracy: 0.90625\n",
      "Validation loss per 100 evaluation steps: 1.7065421342849731\n",
      "Validation Loss: 1.7065421342849731\n",
      "Validation Accuracy: 0.6363636363636364\n",
      "Validation loss per 100 evaluation steps: 0.2898230254650116\n",
      "Validation Loss: 0.2898230254650116\n",
      "Validation Accuracy: 0.921875\n",
      "Validation loss per 100 evaluation steps: 0.11151916533708572\n",
      "Validation Loss: 0.11151916533708572\n",
      "Validation Accuracy: 0.953125\n",
      "Validation loss per 100 evaluation steps: 0.3510945737361908\n",
      "Validation Loss: 0.3510945737361908\n",
      "Validation Accuracy: 0.8703703703703703\n",
      "Validation loss per 100 evaluation steps: 0.15140293538570404\n",
      "Validation Loss: 0.15140293538570404\n",
      "Validation Accuracy: 0.94140625\n",
      "Validation loss per 100 evaluation steps: 0.08622434735298157\n",
      "Validation Loss: 0.08622434735298157\n",
      "Validation Accuracy: 0.9819819819819819\n",
      "Validation loss per 100 evaluation steps: 0.1661740094423294\n",
      "Validation Loss: 0.1661740094423294\n",
      "Validation Accuracy: 0.953125\n",
      "Validation loss per 100 evaluation steps: 0.2535269856452942\n",
      "Validation Loss: 0.2535269856452942\n",
      "Validation Accuracy: 0.95703125\n",
      "Validation loss per 100 evaluation steps: 0.05934680253267288\n",
      "Validation Loss: 0.05934680253267288\n",
      "Validation Accuracy: 0.9767441860465116\n",
      "Validation loss per 100 evaluation steps: 0.4925059378147125\n",
      "Validation Loss: 0.4925059378147125\n",
      "Validation Accuracy: 0.8984375\n",
      "Validation loss per 100 evaluation steps: 0.15080907940864563\n",
      "Validation Loss: 0.15080907940864563\n",
      "Validation Accuracy: 0.97265625\n",
      "Validation loss per 100 evaluation steps: 2.3502373695373535\n",
      "Validation Loss: 2.3502373695373535\n",
      "Validation Accuracy: 0.69921875\n",
      "Validation loss per 100 evaluation steps: 0.06096625328063965\n",
      "Validation Loss: 0.06096625328063965\n",
      "Validation Accuracy: 0.97265625\n",
      "Validation loss per 100 evaluation steps: 0.0008126393076963723\n",
      "Validation Loss: 0.0008126393076963723\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.05858514830470085\n",
      "Validation Loss: 0.05858514830470085\n",
      "Validation Accuracy: 0.96484375\n",
      "Validation loss per 100 evaluation steps: 0.35566088557243347\n",
      "Validation Loss: 0.35566088557243347\n",
      "Validation Accuracy: 0.90234375\n",
      "Validation loss per 100 evaluation steps: 5.390152931213379\n",
      "Validation Loss: 5.390152931213379\n",
      "Validation Accuracy: 0.010638297872340425\n",
      "Validation loss per 100 evaluation steps: 0.01928211748600006\n",
      "Validation Loss: 0.01928211748600006\n",
      "Validation Accuracy: 0.9921875\n",
      "Validation loss per 100 evaluation steps: 1.2561239004135132\n",
      "Validation Loss: 1.2561239004135132\n",
      "Validation Accuracy: 0.671875\n",
      "Validation loss per 100 evaluation steps: 0.9881280660629272\n",
      "Validation Loss: 0.9881280660629272\n",
      "Validation Accuracy: 0.7352941176470589\n",
      "Validation loss per 100 evaluation steps: 0.05270955711603165\n",
      "Validation Loss: 0.05270955711603165\n",
      "Validation Accuracy: 0.97265625\n",
      "Validation loss per 100 evaluation steps: 0.7234894037246704\n",
      "Validation Loss: 0.7234894037246704\n",
      "Validation Accuracy: 0.8898305084745762\n",
      "Validation loss per 100 evaluation steps: 0.5904860496520996\n",
      "Validation Loss: 0.5904860496520996\n",
      "Validation Accuracy: 0.89453125\n",
      "Validation loss per 100 evaluation steps: 2.920071601867676\n",
      "Validation Loss: 2.920071601867676\n",
      "Validation Accuracy: 0.48299319727891155\n",
      "Validation loss per 100 evaluation steps: 0.7001631259918213\n",
      "Validation Loss: 0.7001631259918213\n",
      "Validation Accuracy: 0.79296875\n",
      "Validation loss per 100 evaluation steps: 2.0364937782287598\n",
      "Validation Loss: 2.0364937782287598\n",
      "Validation Accuracy: 0.546875\n",
      "Validation loss per 100 evaluation steps: 0.21461962163448334\n",
      "Validation Loss: 0.21461962163448334\n",
      "Validation Accuracy: 0.9359605911330049\n",
      "Validation loss per 100 evaluation steps: 0.8851618766784668\n",
      "Validation Loss: 0.8851618766784668\n",
      "Validation Accuracy: 0.80859375\n",
      "Validation loss per 100 evaluation steps: 0.32464298605918884\n",
      "Validation Loss: 0.32464298605918884\n",
      "Validation Accuracy: 0.8828125\n",
      "Validation loss per 100 evaluation steps: 0.20774559676647186\n",
      "Validation Loss: 0.20774559676647186\n",
      "Validation Accuracy: 0.9140625\n",
      "Validation loss per 100 evaluation steps: 0.8098036050796509\n",
      "Validation Loss: 0.8098036050796509\n",
      "Validation Accuracy: 0.83203125\n",
      "Validation loss per 100 evaluation steps: 0.32021450996398926\n",
      "Validation Loss: 0.32021450996398926\n",
      "Validation Accuracy: 0.82421875\n",
      "Validation loss per 100 evaluation steps: 0.8250468969345093\n",
      "Validation Loss: 0.8250468969345093\n",
      "Validation Accuracy: 0.78125\n",
      "Validation loss per 100 evaluation steps: 0.7748028039932251\n",
      "Validation Loss: 0.7748028039932251\n",
      "Validation Accuracy: 0.703125\n",
      "Validation loss per 100 evaluation steps: 1.5750186443328857\n",
      "Validation Loss: 1.5750186443328857\n",
      "Validation Accuracy: 0.6953125\n",
      "Validation loss per 100 evaluation steps: 0.9705094695091248\n",
      "Validation Loss: 0.9705094695091248\n",
      "Validation Accuracy: 0.78515625\n",
      "Validation loss per 100 evaluation steps: 0.7147570252418518\n",
      "Validation Loss: 0.7147570252418518\n",
      "Validation Accuracy: 0.6953125\n",
      "Validation loss per 100 evaluation steps: 1.1006697416305542\n",
      "Validation Loss: 1.1006697416305542\n",
      "Validation Accuracy: 0.6190476190476191\n",
      "Validation loss per 100 evaluation steps: 2.2884156703948975\n",
      "Validation Loss: 2.2884156703948975\n",
      "Validation Accuracy: 0.5625\n",
      "Validation loss per 100 evaluation steps: 0.00025273149367421865\n",
      "Validation Loss: 0.00025273149367421865\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.32864853739738464\n",
      "Validation Loss: 0.32864853739738464\n",
      "Validation Accuracy: 0.859375\n",
      "Validation loss per 100 evaluation steps: 0.7893856167793274\n",
      "Validation Loss: 0.7893856167793274\n",
      "Validation Accuracy: 0.7183098591549296\n",
      "Validation loss per 100 evaluation steps: 0.8583348393440247\n",
      "Validation Loss: 0.8583348393440247\n",
      "Validation Accuracy: 0.84765625\n",
      "Validation loss per 100 evaluation steps: 0.7480940222740173\n",
      "Validation Loss: 0.7480940222740173\n",
      "Validation Accuracy: 0.8359375\n",
      "Validation loss per 100 evaluation steps: 0.7718817591667175\n",
      "Validation Loss: 0.7718817591667175\n",
      "Validation Accuracy: 0.83984375\n",
      "Validation loss per 100 evaluation steps: 0.7390183806419373\n",
      "Validation Loss: 0.7390183806419373\n",
      "Validation Accuracy: 0.6388888888888888\n",
      "Validation loss per 100 evaluation steps: 0.3381747603416443\n",
      "Validation Loss: 0.3381747603416443\n",
      "Validation Accuracy: 0.92578125\n",
      "Validation loss per 100 evaluation steps: 0.10841041803359985\n",
      "Validation Loss: 0.10841041803359985\n",
      "Validation Accuracy: 0.953125\n",
      "Validation loss per 100 evaluation steps: 0.8406381607055664\n",
      "Validation Loss: 0.8406381607055664\n",
      "Validation Accuracy: 0.8186274509803921\n",
      "Validation loss per 100 evaluation steps: 0.11162971705198288\n",
      "Validation Loss: 0.11162971705198288\n",
      "Validation Accuracy: 0.95703125\n",
      "Validation loss per 100 evaluation steps: 0.24726590514183044\n",
      "Validation Loss: 0.24726590514183044\n",
      "Validation Accuracy: 0.91796875\n",
      "Validation loss per 100 evaluation steps: 0.09136361628770828\n",
      "Validation Loss: 0.09136361628770828\n",
      "Validation Accuracy: 0.9609375\n",
      "Validation loss per 100 evaluation steps: 0.16677336394786835\n",
      "Validation Loss: 0.16677336394786835\n",
      "Validation Accuracy: 0.9294117647058824\n",
      "Validation loss per 100 evaluation steps: 0.08111482858657837\n",
      "Validation Loss: 0.08111482858657837\n",
      "Validation Accuracy: 0.97265625\n",
      "Validation loss per 100 evaluation steps: 0.09603077918291092\n",
      "Validation Loss: 0.09603077918291092\n",
      "Validation Accuracy: 0.95703125\n",
      "Validation loss per 100 evaluation steps: 0.25994566082954407\n",
      "Validation Loss: 0.25994566082954407\n",
      "Validation Accuracy: 0.9207317073170732\n",
      "Validation loss per 100 evaluation steps: 0.01056916918605566\n",
      "Validation Loss: 0.01056916918605566\n",
      "Validation Accuracy: 0.99609375\n",
      "Validation loss per 100 evaluation steps: 0.4358972907066345\n",
      "Validation Loss: 0.4358972907066345\n",
      "Validation Accuracy: 0.953125\n",
      "Validation loss per 100 evaluation steps: 0.4604422152042389\n",
      "Validation Loss: 0.4604422152042389\n",
      "Validation Accuracy: 0.94921875\n",
      "Validation loss per 100 evaluation steps: 0.14769288897514343\n",
      "Validation Loss: 0.14769288897514343\n",
      "Validation Accuracy: 0.9846938775510204\n",
      "Validation loss per 100 evaluation steps: 0.17410673201084137\n",
      "Validation Loss: 0.17410673201084137\n",
      "Validation Accuracy: 0.93359375\n",
      "Validation loss per 100 evaluation steps: 0.2205621898174286\n",
      "Validation Loss: 0.2205621898174286\n",
      "Validation Accuracy: 0.87890625\n",
      "Validation loss per 100 evaluation steps: 0.5317680835723877\n",
      "Validation Loss: 0.5317680835723877\n",
      "Validation Accuracy: 0.87109375\n",
      "Validation loss per 100 evaluation steps: 0.046975456178188324\n",
      "Validation Loss: 0.046975456178188324\n",
      "Validation Accuracy: 0.97265625\n",
      "Validation loss per 100 evaluation steps: 0.2771953344345093\n",
      "Validation Loss: 0.2771953344345093\n",
      "Validation Accuracy: 0.88268156424581\n",
      "Validation loss per 100 evaluation steps: 0.3985259234905243\n",
      "Validation Loss: 0.3985259234905243\n",
      "Validation Accuracy: 0.89453125\n",
      "Validation loss per 100 evaluation steps: 1.0828969478607178\n",
      "Validation Loss: 1.0828969478607178\n",
      "Validation Accuracy: 0.7578125\n",
      "Validation loss per 100 evaluation steps: 0.00800036545842886\n",
      "Validation Loss: 0.00800036545842886\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.1462380290031433\n",
      "Validation Loss: 0.1462380290031433\n",
      "Validation Accuracy: 0.94140625\n",
      "Validation loss per 100 evaluation steps: 0.12995551526546478\n",
      "Validation Loss: 0.12995551526546478\n",
      "Validation Accuracy: 0.9453125\n",
      "Validation loss per 100 evaluation steps: 0.06808444112539291\n",
      "Validation Loss: 0.06808444112539291\n",
      "Validation Accuracy: 0.98046875\n",
      "Validation loss per 100 evaluation steps: 0.9441470503807068\n",
      "Validation Loss: 0.9441470503807068\n",
      "Validation Accuracy: 0.7169811320754716\n",
      "Validation loss per 100 evaluation steps: 0.5085710287094116\n",
      "Validation Loss: 0.5085710287094116\n",
      "Validation Accuracy: 0.83203125\n",
      "Validation loss per 100 evaluation steps: 0.16741469502449036\n",
      "Validation Loss: 0.16741469502449036\n",
      "Validation Accuracy: 0.9296875\n",
      "Validation loss per 100 evaluation steps: 0.7474707961082458\n",
      "Validation Loss: 0.7474707961082458\n",
      "Validation Accuracy: 0.67578125\n",
      "Validation loss per 100 evaluation steps: 0.8021711111068726\n",
      "Validation Loss: 0.8021711111068726\n",
      "Validation Accuracy: 0.7096774193548387\n",
      "Validation loss per 100 evaluation steps: 0.17859360575675964\n",
      "Validation Loss: 0.17859360575675964\n",
      "Validation Accuracy: 0.95703125\n",
      "Validation loss per 100 evaluation steps: 0.0675087496638298\n",
      "Validation Loss: 0.0675087496638298\n",
      "Validation Accuracy: 0.97265625\n",
      "Validation loss per 100 evaluation steps: 0.07979591935873032\n",
      "Validation Loss: 0.07979591935873032\n",
      "Validation Accuracy: 0.9770114942528736\n",
      "Validation loss per 100 evaluation steps: 0.36351969838142395\n",
      "Validation Loss: 0.36351969838142395\n",
      "Validation Accuracy: 0.859375\n",
      "Validation loss per 100 evaluation steps: 0.03739923983812332\n",
      "Validation Loss: 0.03739923983812332\n",
      "Validation Accuracy: 0.984375\n",
      "Validation loss per 100 evaluation steps: 0.004547424614429474\n",
      "Validation Loss: 0.004547424614429474\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.08970984816551208\n",
      "Validation Loss: 0.08970984816551208\n",
      "Validation Accuracy: 0.96484375\n",
      "Validation loss per 100 evaluation steps: 0.3960839509963989\n",
      "Validation Loss: 0.3960839509963989\n",
      "Validation Accuracy: 0.859375\n",
      "Validation loss per 100 evaluation steps: 0.3107806146144867\n",
      "Validation Loss: 0.3107806146144867\n",
      "Validation Accuracy: 0.92578125\n",
      "Validation loss per 100 evaluation steps: 0.00032362615456804633\n",
      "Validation Loss: 0.00032362615456804633\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.15845471620559692\n",
      "Validation Loss: 0.15845471620559692\n",
      "Validation Accuracy: 0.93359375\n",
      "Validation loss per 100 evaluation steps: 0.9033219814300537\n",
      "Validation Loss: 0.9033219814300537\n",
      "Validation Accuracy: 0.859375\n",
      "Validation loss per 100 evaluation steps: 0.4871194362640381\n",
      "Validation Loss: 0.4871194362640381\n",
      "Validation Accuracy: 0.8057553956834532\n",
      "Validation loss per 100 evaluation steps: 0.21022741496562958\n",
      "Validation Loss: 0.21022741496562958\n",
      "Validation Accuracy: 0.9296875\n",
      "Validation loss per 100 evaluation steps: 0.011325213126838207\n",
      "Validation Loss: 0.011325213126838207\n",
      "Validation Accuracy: 0.99609375\n",
      "Validation loss per 100 evaluation steps: 0.2506967782974243\n",
      "Validation Loss: 0.2506967782974243\n",
      "Validation Accuracy: 0.890625\n",
      "Validation loss per 100 evaluation steps: 0.32350632548332214\n",
      "Validation Loss: 0.32350632548332214\n",
      "Validation Accuracy: 0.8671875\n",
      "Validation loss per 100 evaluation steps: 0.13678163290023804\n",
      "Validation Loss: 0.13678163290023804\n",
      "Validation Accuracy: 0.9375\n",
      "Validation loss per 100 evaluation steps: 0.7877968549728394\n",
      "Validation Loss: 0.7877968549728394\n",
      "Validation Accuracy: 0.7421875\n",
      "Validation loss per 100 evaluation steps: 0.9898843169212341\n",
      "Validation Loss: 0.9898843169212341\n",
      "Validation Accuracy: 0.7163120567375887\n",
      "Validation loss per 100 evaluation steps: 0.05480252206325531\n",
      "Validation Loss: 0.05480252206325531\n",
      "Validation Accuracy: 0.984375\n",
      "Validation loss per 100 evaluation steps: 0.07865781337022781\n",
      "Validation Loss: 0.07865781337022781\n",
      "Validation Accuracy: 0.96875\n",
      "Validation loss per 100 evaluation steps: 0.11110139638185501\n",
      "Validation Loss: 0.11110139638185501\n",
      "Validation Accuracy: 0.9707602339181286\n",
      "Validation loss per 100 evaluation steps: 0.0045046028681099415\n",
      "Validation Loss: 0.0045046028681099415\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.033223625272512436\n",
      "Validation Loss: 0.033223625272512436\n",
      "Validation Accuracy: 0.984375\n",
      "Validation loss per 100 evaluation steps: 0.10916106402873993\n",
      "Validation Loss: 0.10916106402873993\n",
      "Validation Accuracy: 0.9609375\n",
      "Validation loss per 100 evaluation steps: 0.5041342377662659\n",
      "Validation Loss: 0.5041342377662659\n",
      "Validation Accuracy: 0.8359375\n",
      "Validation loss per 100 evaluation steps: 0.17488627135753632\n",
      "Validation Loss: 0.17488627135753632\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.056467585265636444\n",
      "Validation Loss: 0.056467585265636444\n",
      "Validation Accuracy: 0.96875\n",
      "Validation loss per 100 evaluation steps: 0.3299753963947296\n",
      "Validation Loss: 0.3299753963947296\n",
      "Validation Accuracy: 0.91796875\n",
      "Validation loss per 100 evaluation steps: 0.020885489881038666\n",
      "Validation Loss: 0.020885489881038666\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.25505825877189636\n",
      "Validation Loss: 0.25505825877189636\n",
      "Validation Accuracy: 0.8671875\n",
      "Validation loss per 100 evaluation steps: 0.03590357303619385\n",
      "Validation Loss: 0.03590357303619385\n",
      "Validation Accuracy: 0.99609375\n",
      "Validation loss per 100 evaluation steps: 0.46827882528305054\n",
      "Validation Loss: 0.46827882528305054\n",
      "Validation Accuracy: 0.86328125\n",
      "Validation loss per 100 evaluation steps: 0.2184111326932907\n",
      "Validation Loss: 0.2184111326932907\n",
      "Validation Accuracy: 0.90625\n",
      "Validation loss per 100 evaluation steps: 1.0122261047363281\n",
      "Validation Loss: 1.0122261047363281\n",
      "Validation Accuracy: 0.75\n",
      "Validation loss per 100 evaluation steps: 0.18364961445331573\n",
      "Validation Loss: 0.18364961445331573\n",
      "Validation Accuracy: 0.94921875\n",
      "Validation loss per 100 evaluation steps: 0.4816693663597107\n",
      "Validation Loss: 0.4816693663597107\n",
      "Validation Accuracy: 0.828125\n",
      "Validation loss per 100 evaluation steps: 0.5225721001625061\n",
      "Validation Loss: 0.5225721001625061\n",
      "Validation Accuracy: 0.80078125\n",
      "Validation loss per 100 evaluation steps: 1.3757189512252808\n",
      "Validation Loss: 1.3757189512252808\n",
      "Validation Accuracy: 0.7539267015706806\n",
      "Validation loss per 100 evaluation steps: 0.4722801148891449\n",
      "Validation Loss: 0.4722801148891449\n",
      "Validation Accuracy: 0.82421875\n",
      "Validation loss per 100 evaluation steps: 0.20301106572151184\n",
      "Validation Loss: 0.20301106572151184\n",
      "Validation Accuracy: 0.890625\n",
      "Validation loss per 100 evaluation steps: 0.35501039028167725\n",
      "Validation Loss: 0.35501039028167725\n",
      "Validation Accuracy: 0.86328125\n",
      "Validation loss per 100 evaluation steps: 0.24041564762592316\n",
      "Validation Loss: 0.24041564762592316\n",
      "Validation Accuracy: 0.890625\n",
      "Validation loss per 100 evaluation steps: 0.6413241624832153\n",
      "Validation Loss: 0.6413241624832153\n",
      "Validation Accuracy: 0.71484375\n",
      "Validation loss per 100 evaluation steps: 0.5066016912460327\n",
      "Validation Loss: 0.5066016912460327\n",
      "Validation Accuracy: 0.8333333333333334\n",
      "Validation loss per 100 evaluation steps: 0.5861515402793884\n",
      "Validation Loss: 0.5861515402793884\n",
      "Validation Accuracy: 0.8125\n",
      "Validation loss per 100 evaluation steps: 0.6375638246536255\n",
      "Validation Loss: 0.6375638246536255\n",
      "Validation Accuracy: 0.83984375\n",
      "Validation loss per 100 evaluation steps: 0.5451351404190063\n",
      "Validation Loss: 0.5451351404190063\n",
      "Validation Accuracy: 0.828125\n",
      "Validation loss per 100 evaluation steps: 0.2148042917251587\n",
      "Validation Loss: 0.2148042917251587\n",
      "Validation Accuracy: 0.92578125\n",
      "Validation loss per 100 evaluation steps: 0.2706696391105652\n",
      "Validation Loss: 0.2706696391105652\n",
      "Validation Accuracy: 0.86328125\n",
      "Validation loss per 100 evaluation steps: 0.2055818736553192\n",
      "Validation Loss: 0.2055818736553192\n",
      "Validation Accuracy: 0.921875\n",
      "Validation loss per 100 evaluation steps: 0.49448108673095703\n",
      "Validation Loss: 0.49448108673095703\n",
      "Validation Accuracy: 0.7734375\n",
      "Validation loss per 100 evaluation steps: 0.6104973554611206\n",
      "Validation Loss: 0.6104973554611206\n",
      "Validation Accuracy: 0.8246445497630331\n",
      "Validation loss per 100 evaluation steps: 0.00032357353484258056\n",
      "Validation Loss: 0.00032357353484258056\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.11388589441776276\n",
      "Validation Loss: 0.11388589441776276\n",
      "Validation Accuracy: 0.9609375\n",
      "Validation loss per 100 evaluation steps: 0.059707414358854294\n",
      "Validation Loss: 0.059707414358854294\n",
      "Validation Accuracy: 0.9765625\n",
      "Validation loss per 100 evaluation steps: 0.03698967024683952\n",
      "Validation Loss: 0.03698967024683952\n",
      "Validation Accuracy: 0.9868421052631579\n",
      "Validation loss per 100 evaluation steps: 0.0632268562912941\n",
      "Validation Loss: 0.0632268562912941\n",
      "Validation Accuracy: 0.98828125\n",
      "Validation loss per 100 evaluation steps: 0.39347442984580994\n",
      "Validation Loss: 0.39347442984580994\n",
      "Validation Accuracy: 0.8671875\n",
      "Validation loss per 100 evaluation steps: 0.11834432184696198\n",
      "Validation Loss: 0.11834432184696198\n",
      "Validation Accuracy: 0.9557522123893806\n",
      "Validation loss per 100 evaluation steps: 0.14116454124450684\n",
      "Validation Loss: 0.14116454124450684\n",
      "Validation Accuracy: 0.96484375\n",
      "Validation loss per 100 evaluation steps: 0.4498917758464813\n",
      "Validation Loss: 0.4498917758464813\n",
      "Validation Accuracy: 0.92578125\n",
      "Validation loss per 100 evaluation steps: 0.07204743474721909\n",
      "Validation Loss: 0.07204743474721909\n",
      "Validation Accuracy: 0.9644670050761421\n",
      "Validation loss per 100 evaluation steps: 0.33936813473701477\n",
      "Validation Loss: 0.33936813473701477\n",
      "Validation Accuracy: 0.8178137651821862\n",
      "Validation loss per 100 evaluation steps: 0.48196905851364136\n",
      "Validation Loss: 0.48196905851364136\n",
      "Validation Accuracy: 0.8828125\n",
      "Validation loss per 100 evaluation steps: 0.22482988238334656\n",
      "Validation Loss: 0.22482988238334656\n",
      "Validation Accuracy: 0.8671328671328671\n",
      "Validation loss per 100 evaluation steps: 0.5240541100502014\n",
      "Validation Loss: 0.5240541100502014\n",
      "Validation Accuracy: 0.890625\n",
      "Validation loss per 100 evaluation steps: 0.314127653837204\n",
      "Validation Loss: 0.314127653837204\n",
      "Validation Accuracy: 0.91015625\n",
      "Validation loss per 100 evaluation steps: 0.001241397694684565\n",
      "Validation Loss: 0.001241397694684565\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.42115816473960876\n",
      "Validation Loss: 0.42115816473960876\n",
      "Validation Accuracy: 0.89453125\n",
      "Validation loss per 100 evaluation steps: 0.017221881076693535\n",
      "Validation Loss: 0.017221881076693535\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.3304072320461273\n",
      "Validation Loss: 0.3304072320461273\n",
      "Validation Accuracy: 0.8947368421052632\n",
      "Validation loss per 100 evaluation steps: 0.0017838921630755067\n",
      "Validation Loss: 0.0017838921630755067\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.6543610095977783\n",
      "Validation Loss: 0.6543610095977783\n",
      "Validation Accuracy: 0.7748344370860927\n",
      "Validation loss per 100 evaluation steps: 0.3548106551170349\n",
      "Validation Loss: 0.3548106551170349\n",
      "Validation Accuracy: 0.957983193277311\n",
      "Validation loss per 100 evaluation steps: 0.008201684802770615\n",
      "Validation Loss: 0.008201684802770615\n",
      "Validation Accuracy: 0.99609375\n",
      "Validation loss per 100 evaluation steps: 0.09968545287847519\n",
      "Validation Loss: 0.09968545287847519\n",
      "Validation Accuracy: 0.96484375\n",
      "Validation loss per 100 evaluation steps: 0.004962661303579807\n",
      "Validation Loss: 0.004962661303579807\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.3441832959651947\n",
      "Validation Loss: 0.3441832959651947\n",
      "Validation Accuracy: 0.87890625\n",
      "Validation loss per 100 evaluation steps: 0.6818264126777649\n",
      "Validation Loss: 0.6818264126777649\n",
      "Validation Accuracy: 0.7578125\n",
      "Validation loss per 100 evaluation steps: 0.2078147977590561\n",
      "Validation Loss: 0.2078147977590561\n",
      "Validation Accuracy: 0.9240506329113924\n",
      "Validation loss per 100 evaluation steps: 0.0007876877207309008\n",
      "Validation Loss: 0.0007876877207309008\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.22434239089488983\n",
      "Validation Loss: 0.22434239089488983\n",
      "Validation Accuracy: 0.94140625\n",
      "Validation loss per 100 evaluation steps: 0.2283979058265686\n",
      "Validation Loss: 0.2283979058265686\n",
      "Validation Accuracy: 0.9296875\n",
      "Validation loss per 100 evaluation steps: 0.03911157697439194\n",
      "Validation Loss: 0.03911157697439194\n",
      "Validation Accuracy: 0.9866666666666667\n",
      "Validation loss per 100 evaluation steps: 0.02477758564054966\n",
      "Validation Loss: 0.02477758564054966\n",
      "Validation Accuracy: 0.99609375\n",
      "Validation loss per 100 evaluation steps: 0.11764214932918549\n",
      "Validation Loss: 0.11764214932918549\n",
      "Validation Accuracy: 0.9596774193548387\n",
      "Validation loss per 100 evaluation steps: 0.4211204946041107\n",
      "Validation Loss: 0.4211204946041107\n",
      "Validation Accuracy: 0.8203125\n",
      "Validation loss per 100 evaluation steps: 0.2606579065322876\n",
      "Validation Loss: 0.2606579065322876\n",
      "Validation Accuracy: 0.90234375\n",
      "Validation loss per 100 evaluation steps: 0.2785855531692505\n",
      "Validation Loss: 0.2785855531692505\n",
      "Validation Accuracy: 0.9465648854961832\n",
      "Validation loss per 100 evaluation steps: 0.24227476119995117\n",
      "Validation Loss: 0.24227476119995117\n",
      "Validation Accuracy: 0.9375\n",
      "Validation loss per 100 evaluation steps: 1.0609906911849976\n",
      "Validation Loss: 1.0609906911849976\n",
      "Validation Accuracy: 0.69140625\n",
      "Validation loss per 100 evaluation steps: 0.820594847202301\n",
      "Validation Loss: 0.820594847202301\n",
      "Validation Accuracy: 0.5483870967741935\n",
      "Validation loss per 100 evaluation steps: 0.19427016377449036\n",
      "Validation Loss: 0.19427016377449036\n",
      "Validation Accuracy: 0.94140625\n",
      "Validation loss per 100 evaluation steps: 0.4207802712917328\n",
      "Validation Loss: 0.4207802712917328\n",
      "Validation Accuracy: 0.796875\n",
      "Validation loss per 100 evaluation steps: 0.0030126061756163836\n",
      "Validation Loss: 0.0030126061756163836\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.013772939331829548\n",
      "Validation Loss: 0.013772939331829548\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.27350252866744995\n",
      "Validation Loss: 0.27350252866744995\n",
      "Validation Accuracy: 0.88671875\n",
      "Validation loss per 100 evaluation steps: 0.6530300378799438\n",
      "Validation Loss: 0.6530300378799438\n",
      "Validation Accuracy: 0.890625\n",
      "Validation loss per 100 evaluation steps: 0.5087979435920715\n",
      "Validation Loss: 0.5087979435920715\n",
      "Validation Accuracy: 0.86328125\n",
      "Validation loss per 100 evaluation steps: 0.5924718379974365\n",
      "Validation Loss: 0.5924718379974365\n",
      "Validation Accuracy: 0.7637130801687764\n",
      "Validation loss per 100 evaluation steps: 0.2028467357158661\n",
      "Validation Loss: 0.2028467357158661\n",
      "Validation Accuracy: 0.95703125\n",
      "Validation loss per 100 evaluation steps: 0.10068006068468094\n",
      "Validation Loss: 0.10068006068468094\n",
      "Validation Accuracy: 0.9609375\n",
      "Validation loss per 100 evaluation steps: 0.3944697678089142\n",
      "Validation Loss: 0.3944697678089142\n",
      "Validation Accuracy: 0.90234375\n",
      "Validation loss per 100 evaluation steps: 0.27836063504219055\n",
      "Validation Loss: 0.27836063504219055\n",
      "Validation Accuracy: 0.908695652173913\n",
      "Validation loss per 100 evaluation steps: 0.14800673723220825\n",
      "Validation Loss: 0.14800673723220825\n",
      "Validation Accuracy: 0.94921875\n",
      "Validation loss per 100 evaluation steps: 0.24098557233810425\n",
      "Validation Loss: 0.24098557233810425\n",
      "Validation Accuracy: 0.8984375\n",
      "Validation loss per 100 evaluation steps: 0.2911408841609955\n",
      "Validation Loss: 0.2911408841609955\n",
      "Validation Accuracy: 0.84765625\n",
      "Validation loss per 100 evaluation steps: 0.4237840473651886\n",
      "Validation Loss: 0.4237840473651886\n",
      "Validation Accuracy: 0.788235294117647\n",
      "Validation loss per 100 evaluation steps: 0.14310197532176971\n",
      "Validation Loss: 0.14310197532176971\n",
      "Validation Accuracy: 0.95703125\n",
      "Validation loss per 100 evaluation steps: 0.4276266396045685\n",
      "Validation Loss: 0.4276266396045685\n",
      "Validation Accuracy: 0.8828125\n",
      "Validation loss per 100 evaluation steps: 0.040520988404750824\n",
      "Validation Loss: 0.040520988404750824\n",
      "Validation Accuracy: 0.98828125\n",
      "Validation loss per 100 evaluation steps: 0.0005223616608418524\n",
      "Validation Loss: 0.0005223616608418524\n",
      "Validation Accuracy: 1.0\n",
      "Validation loss per 100 evaluation steps: 0.21238656342029572\n",
      "Validation Loss: 0.21238656342029572\n",
      "Validation Accuracy: 0.9140625\n",
      "Validation loss per 100 evaluation steps: 0.07115551829338074\n",
      "Validation Loss: 0.07115551829338074\n",
      "Validation Accuracy: 0.98046875\n",
      "Validation loss per 100 evaluation steps: 0.7101304531097412\n",
      "Validation Loss: 0.7101304531097412\n",
      "Validation Accuracy: 0.84765625\n",
      "Validation loss per 100 evaluation steps: 0.02570517733693123\n",
      "Validation Loss: 0.02570517733693123\n",
      "Validation Accuracy: 0.991869918699187\n"
     ]
    }
   ],
   "source": [
    "# Run 1 by 1\n",
    "prediction_map = {}\n",
    "actual_labels_map = {}\n",
    "\n",
    "for i in range(len(dev_df)):\n",
    "    single_dev_row = pd.DataFrame(columns = ['text','labels'])\n",
    "    single_dev_row.loc[0, 'text'] = dev_df.loc[i].text\n",
    "    single_dev_row.loc[0, 'labels'] = dev_df.loc[i].labels\n",
    "\n",
    "    dev_set = dataset(single_dev_row, tokenizer, MAX_LEN)\n",
    "    dev_loader = DataLoader(dev_set, **dev_params)\n",
    "    labels, predictions = valid(model, dev_loader)\n",
    "    if dev_id[i] not in prediction_map:\n",
    "        prediction_map[dev_id[i]] = []\n",
    "    prediction_map[dev_id[i]].append(predictions)\n",
    "    if dev_id[i] not in actual_labels_map:\n",
    "        actual_labels_map[dev_id[i]] = []\n",
    "    actual_labels_map[dev_id[i]].append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Snedxm-RVx4",
    "outputId": "dbce42ff-fdcd-4297-cdf0-d9545dafc6f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LV29UG52tu6Z",
    "outputId": "62a9747d-878d-447e-ba9b-faef70e27493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.02570517733693123\n",
      "Validation Loss: 0.02570517733693123\n",
      "Validation Accuracy: 0.991869918699187\n"
     ]
    }
   ],
   "source": [
    "labels_actual, predictions = valid(model, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quAwl4AWCyEr",
    "outputId": "2ef0f30f-3538-471c-8f11-012933662018"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220.54580152671755, 262)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_word_len = []\n",
    "for article in dev_df.text:\n",
    "    total_word_len.append(len(article.split(' ')))\n",
    "np.mean(total_word_len), len(dev_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlWxIsqpBp8h",
    "outputId": "60df0ef8-378c-4cb8-ad79-16033a701ebb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0, 120, 123)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.count('I-Prop'), predictions.count('B-Prop'), predictions.count('O'), len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lL8HwGRGBvk6",
    "outputId": "53716d27-d44a-4eab-b17f-0e3e985d0a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 I-Prop\n",
      "47 I-Prop\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "correct_word_prediction = 0\n",
    "for index in range(len(labels)):\n",
    "  if labels[index] == predictions[index] and labels[index] is not 'O':\n",
    "    correct_word_prediction+=1\n",
    "    print(index, labels[index])\n",
    "\n",
    "print(correct_word_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEB9WtzxDfql"
   },
   "outputs": [],
   "source": [
    "task_SI_output_file = '/content/drive/MyDrive/NLP/project_5_data/bert_base_SI_output_256tokens_e6.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UStya64eUqo",
    "outputId": "1bc72497-136d-4f2b-d2cc-f08bb700e9bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FqPMj7LlrVg"
   },
   "outputs": [],
   "source": [
    "with open(task_SI_output_file, \"w\") as fout:\n",
    "    \n",
    "    for dev_article_id in dev_articles.keys():\n",
    "        print(\"Processing:\", dev_article_id)\n",
    "        article_text = dev_articles[dev_article_id]\n",
    "        predictions_list = prediction_map[dev_article_id]\n",
    "\n",
    "        print(\"Word count in article:\", len(article_text.replace('\\n\\n','\\n').replace('\\n', ' ').strip().split(' ')))\n",
    "\n",
    "        # pred_labels = [0] * len(predictions)\n",
    "        # for i in range(len(predictions)):\n",
    "        #     if predictions[i] == 'I-Prop':\n",
    "        #         pred_labels[i] = 1\n",
    "        \n",
    "        pred_labels = []\n",
    "        for predictions in predictions_list:\n",
    "            for temp_pred_label in predictions:\n",
    "                if temp_pred_label == 'I-Prop':\n",
    "                    pred_labels.append(1)\n",
    "                else:\n",
    "                    pred_labels.append(0)\n",
    "        print(\"Prediction length for article {0:9}:{1:5}\".format(dev_article_id, len(pred_labels)))\n",
    "\n",
    "        char_index = 0\n",
    "        span_started = False\n",
    "        span_len = 0\n",
    "        label_index = 0\n",
    "        idx = 0\n",
    "\n",
    "        while idx < len(article_text) and label_index < len(pred_labels):\n",
    "        # for idx in range(len(article_text)):\n",
    "            # print(\"idx: {0:5}, char: {1:2}, label_idx: {2:5}\".format(idx, article_text[idx], label_index))\n",
    "\n",
    "            if (article_text[idx:idx+2] == '\\n\\n') and span_started:\n",
    "                idx += 2\n",
    "                label_index += 1\n",
    "                span_len += 2\n",
    "                continue\n",
    "            elif (article_text[idx:idx+2] == '\\n\\n'):\n",
    "                idx += 2\n",
    "                label_index +=1\n",
    "                continue\n",
    "            if (article_text[idx] == ' ' or article_text[idx] == '\\n') and span_started:\n",
    "                label_index += 1\n",
    "                span_len += 1\n",
    "                idx += 1\n",
    "                continue\n",
    "            elif article_text[idx] == ' ' or article_text[idx] == '\\n':\n",
    "                label_index += 1\n",
    "                idx += 1\n",
    "                continue\n",
    "                        \n",
    "            if pred_labels[label_index] == 1 and not span_started:\n",
    "                span_started = True\n",
    "                start = idx\n",
    "                span_len += 1\n",
    "            elif pred_labels[label_index] == 1 and span_started:\n",
    "                span_len += 1\n",
    "            elif pred_labels[label_index] == 0 and span_started:\n",
    "                span_started = False          \n",
    "                if span_len > 0:\n",
    "                    fout.write(\"%s\\t%s\\t%s\\n\" % (dev_article_id, start, start+span_len))\n",
    "                    span_len = 0\n",
    "            idx += 1\n",
    "        print(\"Done Processing\\n\")\n",
    "    print(\"Predictions writted to file: \", task_SI_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQehQPP8---9"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/NLP/\n",
    "!python3 task-SI_scorer.py -s project_5_data/bert_base_SI_output_256tokens_e6.txt -r project_5_data/datasets/dev-labels-task-si/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Phase3_SI_preprocess_BIO_bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "088b20a3ec274b85b036a5d57cbce488": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e1cd53f0ee5408489ee8cc97bd78ff0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f088e6567084637a9d4bf339978175c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8aa2bb2722714a438527772ebeddf1da",
       "IPY_MODEL_fcf0a233fcde4314b10e1a5076422b6a",
       "IPY_MODEL_8629b2eb57084fd2a2a7241daafa614f"
      ],
      "layout": "IPY_MODEL_088b20a3ec274b85b036a5d57cbce488"
     }
    },
    "32e0a78b254745a783fc3412886e324c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33677c96c34c4cdf94c352cc2a8ab365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a07db69e1b3b4ad7b998544de1aa1f8c",
      "placeholder": "​",
      "style": "IPY_MODEL_86ef9b2a73f146b8aeb9a0150d3d785d",
      "value": "Downloading: 100%"
     }
    },
    "3799f9991c6f47dfbeef4aa9006f568b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d64e49760e740bf869460d7a55cf502": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41ae8d01a95c4c0b809e1f2fa4a0d969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a27b2173bc24358a41e5b8a17ae2503",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ac991660dff47c98458e707fbd5dafe",
      "value": 433
     }
    },
    "49a9c2438aeb4c8caaadc37cd1099f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fd958732ad644a891a017330465644d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51b43206e99c41489b6581846a267025": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32e0a78b254745a783fc3412886e324c",
      "placeholder": "​",
      "style": "IPY_MODEL_82629a9d13cc4051928e8399ab374c83",
      "value": " 433/433 [00:00&lt;00:00, 10.6kB/s]"
     }
    },
    "534dc8078add4bd895a22fc52bc25c18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e1cd53f0ee5408489ee8cc97bd78ff0",
      "placeholder": "​",
      "style": "IPY_MODEL_49a9c2438aeb4c8caaadc37cd1099f87",
      "value": " 436M/436M [00:11&lt;00:00, 35.5MB/s]"
     }
    },
    "56cc4a25122c480098a7df15cdefc3d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5760ab3c75dd4e80b7232703a00c0d07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62cbd534684c47a9b8395fabd4a3fbdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fe36b3e72624b10957e06f8516d7d1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33677c96c34c4cdf94c352cc2a8ab365",
       "IPY_MODEL_88c1920c84e64737b0d158697c30fd9c",
       "IPY_MODEL_534dc8078add4bd895a22fc52bc25c18"
      ],
      "layout": "IPY_MODEL_62cbd534684c47a9b8395fabd4a3fbdd"
     }
    },
    "7cf03e6380ab4029a2fed2e32c4e62e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82629a9d13cc4051928e8399ab374c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8629b2eb57084fd2a2a7241daafa614f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d64e49760e740bf869460d7a55cf502",
      "placeholder": "​",
      "style": "IPY_MODEL_4fd958732ad644a891a017330465644d",
      "value": " 213k/213k [00:00&lt;00:00, 1.35MB/s]"
     }
    },
    "86ef9b2a73f146b8aeb9a0150d3d785d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88c1920c84e64737b0d158697c30fd9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be101f8a16e8403298554172effc6b24",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_91bdbc75bd094cc38eaec64779318e06",
      "value": 435779157
     }
    },
    "8aa2bb2722714a438527772ebeddf1da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd5f97572eac468fbb71ed586c3ce6f9",
      "placeholder": "​",
      "style": "IPY_MODEL_3799f9991c6f47dfbeef4aa9006f568b",
      "value": "Downloading: 100%"
     }
    },
    "90bd1a934ba547aab2a88d78b546434d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91bdbc75bd094cc38eaec64779318e06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9a27b2173bc24358a41e5b8a17ae2503": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ac991660dff47c98458e707fbd5dafe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a07db69e1b3b4ad7b998544de1aa1f8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be101f8a16e8403298554172effc6b24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd5f97572eac468fbb71ed586c3ce6f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eefc9bb93bc741aa8d8a0096d2e0ccb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5760ab3c75dd4e80b7232703a00c0d07",
      "placeholder": "​",
      "style": "IPY_MODEL_f035dc4f96d242ab817d3d7926bcb27f",
      "value": "Downloading: 100%"
     }
    },
    "f035dc4f96d242ab817d3d7926bcb27f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1cdaa5e89694501bcfa8a72922f602d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eefc9bb93bc741aa8d8a0096d2e0ccb8",
       "IPY_MODEL_41ae8d01a95c4c0b809e1f2fa4a0d969",
       "IPY_MODEL_51b43206e99c41489b6581846a267025"
      ],
      "layout": "IPY_MODEL_90bd1a934ba547aab2a88d78b546434d"
     }
    },
    "fcf0a233fcde4314b10e1a5076422b6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cf03e6380ab4029a2fed2e32c4e62e3",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56cc4a25122c480098a7df15cdefc3d5",
      "value": 213450
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
