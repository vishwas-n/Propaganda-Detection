{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxvprNVGdF0N"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "udfnbsiTe6u0"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import codecs\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "from torch import cuda, tensor\n",
    "from sklearn import preprocessing\n",
    "from transformers import Trainer, TrainingArguments, RobertaForSequenceClassification, RobertaTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLY12ECuf4th",
    "outputId": "c2c7c4dd-bc6e-43f6-f125-e177a8c7a9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EJCn4kOf5X6",
    "outputId": "86ff6591-a8d5-464e-80e2-0b84a9bcabb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PIUsyf4SgDA_"
   },
   "outputs": [],
   "source": [
    "train_folder = \"/content/drive/MyDrive/NLP/project_5_data/datasets/train-articles\" \n",
    "dev_folder = \"/content/drive/MyDrive/NLP/project_5_data/datasets/dev-articles\"     \n",
    "train_labels_file = \"/content/drive/MyDrive/NLP/project_5_data/datasets/train-task-flc-tc.labels\"\n",
    "# dev_template_labels_file = \"../datasets/test-task-tc-template.out\"\n",
    "dev_template_labels_file = \"/content/drive/MyDrive/NLP/project_5_data/datasets/dev-task-flc-tc.labels\"\n",
    "task_TC_output_file = \"/content/drive/MyDrive/NLP/roberta_TC_final.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Sg33ZokLgoy0"
   },
   "outputs": [],
   "source": [
    "def read_articles_from_file_list(folder_name, file_pattern=\"*.txt\"):\n",
    "    file_list = glob.glob(os.path.join(folder_name, file_pattern))\n",
    "    articles = {}\n",
    "    for filename in sorted(file_list):\n",
    "        article_id = os.path.basename(filename).split(\".\")[0][7:]\n",
    "        with codecs.open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "            articles[article_id] = f.read()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nzeWR7dZgqyr"
   },
   "outputs": [],
   "source": [
    "def read_predictions_from_file(filename):\n",
    "    articles_id, span_starts, span_ends, gold_labels = ([], [], [], [])\n",
    "    with open(filename, \"r\") as f:\n",
    "        for row in f.readlines():\n",
    "            article_id, gold_label, span_start, span_end = row.rstrip().split(\"\\t\")\n",
    "            articles_id.append(article_id)\n",
    "            gold_labels.append(gold_label)\n",
    "            span_starts.append(span_start)\n",
    "            span_ends.append(span_end)\n",
    "    return articles_id, span_starts, span_ends, gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FpRh7iSEgq-_"
   },
   "outputs": [],
   "source": [
    "def get_texts(articles_map, article_ids, span_starts, span_ends):\n",
    "    texts = []\n",
    "    for article_id, sp_start, sp_end in zip(article_ids, span_starts, span_ends):\n",
    "        sentence = articles_map.get(article_id)[int(sp_start):int(sp_end)]\n",
    "        # texts.append(sentence.lower())\n",
    "        texts.append(sentence)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RtMMQP0MgrBW"
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "articles_map = read_articles_from_file_list(train_folder)\n",
    "dev_articles_map = read_articles_from_file_list(dev_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhQ_c_Q0hfRG"
   },
   "outputs": [],
   "source": [
    "len(articles_map), len(dev_articles_map), len(set(articles_map.keys())), len(set(dev_articles_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3a3EhaAgrD4"
   },
   "outputs": [],
   "source": [
    "# reading data from the train set\n",
    "train_articles_ids, train_span_starts, train_span_ends, train_labels = read_predictions_from_file(train_labels_file)\n",
    "print(\"Loaded training %d annotations from %d train articles\" % (len(train_span_starts), len(set(train_articles_ids))))\n",
    "train_texts = get_texts(articles_map, train_articles_ids, train_span_starts, train_span_ends)\n",
    "\n",
    "# reading data from the development set\n",
    "dev_article_ids, dev_span_starts, dev_span_ends, dev_labels = read_predictions_from_file(dev_template_labels_file)\n",
    "print(\"Loaded dev %d annotations from %d dev articles\" % (len(dev_span_starts), len(set(dev_article_ids))))\n",
    "dev_texts = get_texts(dev_articles_map, dev_article_ids, dev_span_starts, dev_span_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1j9latgZhwzC",
    "outputId": "5bf2476e-7864-4c29-973f-d00bb83b4be8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6128, 1063)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts), len(dev_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OlLE8av_grGd"
   },
   "outputs": [],
   "source": [
    "#label_encoding data for the labels\n",
    "le.fit(train_labels)\n",
    "label_to_class_map = {label: clas for label,clas in zip(le.transform(le.classes_), le.classes_)}\n",
    "class_to_label_map = {clas: label  for label,clas in zip(le.transform(le.classes_), le.classes_)}\n",
    "\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "dev_labels_encoded = le.transform(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QFISFARpgrIy"
   },
   "outputs": [],
   "source": [
    "class TC_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OjPpm6fgrLF"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=14)\n",
    "model.to(device)\n",
    "\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EimHGgFGgrNg"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "dev_encodings = tokenizer(dev_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_dataset = TC_Dataset(train_encodings, train_labels_encoded)\n",
    "dev_dataset = TC_Dataset(dev_encodings, dev_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcQdDb8XgrP4"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= '/content/drive/MyDrive/NLP',          # output directory\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,   # batch size per device during training\n",
    "    per_device_eval_batch_size=16,    # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir= '/content/drive/MyDrive/NLP',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=dev_dataset)\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9q-DKA9siq1X"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP/RoBERTa_Task_TC_sd.pt\")\n",
    "# model = BertForSequenceClassification()\n",
    "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/RoBERTa_Task_TC_sd.pt\"))\n",
    "# model.eval()\n",
    "\n",
    "torch.save(model, \"/content/drive/MyDrive/NLP/RoBERTa_Task_TC.pt\")\n",
    "# model = torch.load(\"/content/drive/MyDrive/NLP/RoBERTa_Task_TC.pt\", map_location=torch.device('cpu'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQjh_FjqzcqE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "m1C5kfuTzcsR"
   },
   "outputs": [],
   "source": [
    "def stats(dev_article_ids, dev_span_starts, dev_span_ends):\n",
    "    count_map = {}\n",
    "    for id, start, end in zip(dev_article_ids, dev_span_starts, dev_span_ends):\n",
    "        if id not in count_map:\n",
    "            count_map[id] = {}\n",
    "        if start not in count_map[id]:\n",
    "            count_map[id][start] = {}\n",
    "        if end not in count_map[id][start]:\n",
    "            count_map[id][start][end] = 1\n",
    "        else:\n",
    "            count_map[id][start][end] += 1\n",
    "\n",
    "    # return_map = {}\n",
    "    for id in count_map.keys():\n",
    "        for start in count_map[id].keys():\n",
    "            for end in count_map[id][start].keys():\n",
    "                if count_map[id][start][end] > 1:\n",
    "                    print((id, start, end, count_map[id][start][end]))\n",
    "                    # return_map[id] = (start, end, count_map[id][start][end])\n",
    "    return count_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VQON3emzcu0"
   },
   "outputs": [],
   "source": [
    "# Multi-Label Classification - ONLY DEV Dataset\n",
    "# TC_scorer required Multi-Label classificication in certain format \n",
    "# Also the scorer requires fixed number of predictions and writing more labels will throw an error\n",
    "\n",
    "model.eval()\n",
    "result = 0\n",
    "predictions = []\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "multi_label_id_span_map = stats(dev_article_ids, dev_span_starts, dev_span_ends)\n",
    "processed_article_ids = []\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Running Model for Classification\")\n",
    "with torch.no_grad():\n",
    "    result = model(dev_dataset[0:len(dev_dataset)]['input_ids'].to(device),\n",
    "                    attention_mask=dev_dataset[0:len(dev_dataset)]['attention_mask'].to(device),\n",
    "                    labels=dev_dataset[0:len(dev_dataset)]['labels'].to(device))\n",
    "    \n",
    "    logits = result[1]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.append(logits)\n",
    "\n",
    "final_predictions = []\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "print(\"Computing Predictions and Writing output to file\")\n",
    "with open(task_TC_output_file, \"w\") as fout:\n",
    "    for article_id, prediction, span_start, span_end in zip(dev_article_ids, predictions, dev_span_starts, dev_span_ends):\n",
    "\n",
    "        pred_probas = sigmoid(tensor(prediction))\n",
    "        #Get multiple labels\n",
    "        if multi_label_id_span_map[article_id][span_start][span_end] > 1 and article_id+str(span_start)+str(span_end) not in processed_article_ids:\n",
    "            processed_article_ids.append(article_id+str(span_start)+str(span_end))\n",
    "            \n",
    "            count = multi_label_id_span_map[article_id][span_start][span_end]\n",
    "\n",
    "            pred_labels = np.argsort(pred_probas.tolist())[-1:-(1+count):-1]\n",
    "            predictions_for_article_id = [label_to_class_map[label.item()] for label in pred_labels]\n",
    "\n",
    "            for pred_class in predictions_for_article_id:\n",
    "                final_predictions.append(pred_class)\n",
    "                fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, pred_class, span_start, span_end))\n",
    "        #Get the highest scoring label if none of the labels pass the cutoff\n",
    "        elif article_id+str(span_start)+str(span_end) not in processed_article_ids:\n",
    "            pred_label = np.argmax(pred_probas)\n",
    "            pred_class = label_to_class_map[pred_label.item()]\n",
    "            final_predictions.append(pred_class)\n",
    "            fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, pred_class, span_start, span_end))\n",
    "\n",
    "print(\"Sample final_predictions:\\n\", final_predictions[0:5])\n",
    "print(len(final_predictions))\n",
    "print(\"Predictions written to file \" + task_TC_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2vLxnzkzc2U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0k5yiYvbzc5X"
   },
   "outputs": [],
   "source": [
    "#Uncomment Below cells to perform single label classification. Refer the cell further below for True Multi-Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XvauppXvaio"
   },
   "outputs": [],
   "source": [
    "# #Single Label Classification\n",
    "\n",
    "model.eval()\n",
    "result = 0\n",
    "predictions,  true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "  result = model(dev_dataset[0:len(dev_dataset)]['input_ids'].to(device),\n",
    "                   attention_mask=dev_dataset[0:len(dev_dataset)]['attention_mask'].to(device),\n",
    "                   labels=dev_dataset[0:len(dev_dataset)]['labels'].to(device))\n",
    "  \n",
    "logits = result[1]\n",
    "\n",
    "logits = logits.detach().cpu().numpy()\n",
    "true_label_ids = dev_dataset[0:len(dev_dataset)]['labels'].to('cpu').numpy()\n",
    "  \n",
    "# Store predictions and true labels\n",
    "predictions.append(logits)\n",
    "true_labels.append(true_label_ids)\n",
    "\n",
    "\n",
    "\n",
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "\n",
    "print(flat_predictions.shape, flat_true_labels.shape)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(flat_predictions)):\n",
    "  if flat_predictions[i] == flat_true_labels[i]:\n",
    "    count += 1\n",
    "\n",
    "print(count/len(flat_true_labels))\n",
    "label_to_class_map[flat_predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko7kxmpUxbeV"
   },
   "outputs": [],
   "source": [
    "# #Single Label Classification\n",
    "# # Write results to file\n",
    "# with open(\"/content/drive/MyDrive/NLP/roberta_TC_final.txt\", \"w\") as fout:\n",
    "#     for article_id, prediction, span_start, span_end in zip(dev_article_ids, flat_predictions, dev_span_starts, dev_span_ends):\n",
    "#         fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, label_to_class_map[prediction], span_start, span_end))\n",
    "# print(\"Predictions written to file \" + \"/content/drive/MyDrive/NLP/roberta_TC_final.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xCXbM4TmxIc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaVUsNQ21Uyl"
   },
   "outputs": [],
   "source": [
    "#Uncomment Below cells to perform true multi-label classification. May cause scoring issues if run on dev dataset and the file generated is used for scorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miCm6Ex31GEg",
    "outputId": "4b2c06f6-4ffe-4588-d160-9604893ec184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the model for multi-label classification\n",
      "Computing Predictions \n",
      "Sample final_predictions:\n",
      " [['Name_Calling,Labeling'], ['Name_Calling,Labeling']]\n",
      "Writing Output to File\n",
      "Predictions written to file /content/drive/MyDrive/NLP/results/roberta_TC_final.txt\n"
     ]
    }
   ],
   "source": [
    "# # Actual Multi-label Predictions\n",
    "# # Multi Label Classification - not Dev data case\n",
    "# # Get all predictions over a certain cut-off\n",
    "# model.eval()\n",
    "# result = 0\n",
    "# predictions = []\n",
    "# sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "# print(\"Running the model for multi-label classification\")\n",
    "# with torch.no_grad():\n",
    "#     result = model(dev_dataset[0:len(dev_dataset)]['input_ids'].to(device),\n",
    "#                     attention_mask=dev_dataset[0:len(dev_dataset)]['attention_mask'].to(device),\n",
    "#                     labels=dev_dataset[0:len(dev_dataset)]['labels'].to(device))\n",
    "    \n",
    "#     logits = result[1]\n",
    "#     logits = logits.detach().cpu().numpy()\n",
    "#     predictions.append(logits)\n",
    "\n",
    "# final_predictions = []\n",
    "# predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# print(\"Computing Predictions \")\n",
    "# for prediction in predictions:\n",
    "#     pred_probas = sigmoid(tensor(prediction))\n",
    "\n",
    "#     pred_probas_cutoff = np.zeros(pred_probas.shape)\n",
    "#     pred_probas_cutoff[np.where(pred_probas >= 0.95)] = 1\n",
    "\n",
    "#     if sum(pred_probas_cutoff) == 0:\n",
    "#         pred_probas_cutoff[np.argmax(pred_probas)] = 1\n",
    "    \n",
    "#     predicted_classes = [label_to_class_map[idx] for idx, label in enumerate(pred_probas_cutoff) if label == 1.0]\n",
    "#     final_predictions.append(predicted_classes)\n",
    "\n",
    "# print(\"Sample final_predictions:\\n\", final_predictions[0:7])\n",
    "\n",
    "# print(\"Writing Output to File\")\n",
    "# with open(task_TC_output_file, \"w\") as fout:\n",
    "#     for article_id, prediction_list, span_start, span_end in zip(dev_article_ids, final_predictions, dev_span_starts, dev_span_ends):\n",
    "#         for prediction in prediction_list:\n",
    "#             fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, prediction, span_start, span_end))\n",
    "\n",
    "# print(\"Predictions written to file \" + task_TC_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiiLvVk81GHB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccaw1tUSmjFc"
   },
   "outputs": [],
   "source": [
    "#Scorer code, File paths may vary. Download the file prediction written and please follow the instructions in readme file to get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zgx0AJt1oP93",
    "outputId": "3ed051f8-cab6-4933-d3bd-73e1408b68b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/NLP\n",
      "2022-05-13 23:01:29,419 - INFO - Checking format: User Predictions -- Gold Annotations\n",
      "2022-05-13 23:01:29,421 - INFO - OK: submission file format appears to be correct\n",
      "2022-05-13 23:01:29,461 - INFO - Scoring submission\n",
      "F1=0.614299\n",
      "Precision=0.614299\n",
      "Recall=0.614299\n",
      "F1_Appeal_to_Authority=0.14285714285714285\n",
      "F1_Appeal_to_fear-prejudice=0.3908045977011494\n",
      "F1_Bandwagon,Reductio_ad_hitlerum=0.42857142857142855\n",
      "F1_Black-and-White_Fallacy=0.23529411764705885\n",
      "F1_Causal_Oversimplification=0.4878048780487805\n",
      "F1_Doubt=0.5467625899280576\n",
      "F1_Exaggeration,Minimisation=0.48366013071895425\n",
      "F1_Flag-Waving=0.7471264367816093\n",
      "F1_Loaded_Language=0.7785817655571636\n",
      "F1_Name_Calling,Labeling=0.7002652519893899\n",
      "F1_Repetition=0.411522633744856\n",
      "F1_Slogans=0.5714285714285715\n",
      "F1_Thought-terminating_Cliches=0.20000000000000004\n",
      "F1_Whataboutism,Straw_Men,Red_Herring=0.13333333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %cd /content/drive/MyDrive/NLP/\n",
    "\n",
    "# !python3 project_5_data/propaganda-techniques-scorer/task-TC_scorer.py -s roberta_TC_ML_iter2.txt -r project_5_data/propaganda-techniques-scorer/dev-task-flc-tc.labels -p project_5_data/propaganda-techniques-scorer/propaganda-techniques-names-semeval2020task11.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_TC_RoBERTa_iter1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
